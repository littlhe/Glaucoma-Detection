{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet50MAINPrePro200.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x93aYwu8ISs5"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import keras\n",
        "import pickle\n",
        "import numpy as np\n",
        "# Get a ResNet50 model\n",
        "def resnet50_model(classes=1000, *args, **kwargs):\n",
        "    # Load a model if we have saved one\n",
        "    if(os.path.isfile('/content/drive/MyDrive/resnet_50.h5') == True):\n",
        "        return keras.models.load_model('/content/drive/MyDrive/resnet_50.h5')\n",
        "    # Create an input layer \n",
        "    input = keras.layers.Input(shape=(None, None, 3))\n",
        "    # Create output layers\n",
        "    output = keras.layers.ZeroPadding2D(padding=3, name='padding_conv1')(input)\n",
        "    output = keras.layers.Conv2D(64, (7, 7), strides=(2, 2), use_bias=False, name='conv1')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, epsilon=1e-5, name='bn_conv1')(output)\n",
        "    output = keras.layers.Activation('relu', name='conv1_relu')(output)\n",
        "    output = keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='pool1')(output)\n",
        "    output = conv_block(output, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    output = identity_block(output, 3, [64, 64, 256], stage=2, block='b')\n",
        "    output = identity_block(output, 3, [64, 64, 256], stage=2, block='c')\n",
        "    output = conv_block(output, 3, [128, 128, 512], stage=3, block='a')\n",
        "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='b')\n",
        "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='c')\n",
        "    output = identity_block(output, 3, [128, 128, 512], stage=3, block='d')\n",
        "    output = conv_block(output, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    output = identity_block(output, 3, [256, 256, 1024], stage=4, block='f')\n",
        "    output = conv_block(output, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    output = identity_block(output, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    output = identity_block(output, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    output = keras.layers.GlobalAveragePooling2D(name='pool5')(output)\n",
        "    output = keras.layers.Dense(classes, activation='softmax', name='fc1000')(output)\n",
        "    # Create a model from input layer and output layers\n",
        "    model = keras.models.Model(inputs=input, outputs=output, *args, **kwargs)\n",
        "    # Print model\n",
        "    print()\n",
        "    print(model.summary(), '\\n')\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.adam(lr=0.01, clipnorm=0.001), metrics=['accuracy'])\n",
        "    # Return a model\n",
        "    return model\n",
        "# Create an identity block\n",
        "def identity_block(input, kernel_size, filters, stage, block):\n",
        "    \n",
        "    # Variables\n",
        "    filters1, filters2, filters3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    # Create layers\n",
        "    output = keras.layers.Conv2D(filters1, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters3, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2c')(output)\n",
        "    output = keras.layers.add([output, input])\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    # Return a block\n",
        "    return output\n",
        "# Create a convolution block\n",
        "def conv_block(input, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    # Variables\n",
        "    filters1, filters2, filters3 = filters\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    # Create block layers\n",
        "    output = keras.layers.Conv2D(filters1, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base + '2a')(input)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2a')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters2, kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2b')(output)\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    output = keras.layers.Conv2D(filters3, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(output)\n",
        "    output = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '2c')(output)\n",
        "    shortcut = keras.layers.Conv2D(filters3, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base + '1')(input)\n",
        "    shortcut = keras.layers.BatchNormalization(axis=3, name=bn_name_base + '1')(shortcut)\n",
        "    output = keras.layers.add([output, shortcut])\n",
        "    output = keras.layers.Activation('relu')(output)\n",
        "    # Return a block\n",
        "    return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a model\n",
        "def train():\n",
        "    # Variables, 25 epochs so far\n",
        "    epochs = 200\n",
        "    batch_size = 3\n",
        "    train_samples = 10 * 1 # 10 categories with 5000 images in each category\n",
        "    validation_samples = 10 * 1 # 10 categories with 1000 images in each category\n",
        "    img_width, img_height = 224, 224\n",
        "    # Get the model (10 categories)\n",
        "    model = resnet50_model(10)\n",
        "    # Create a data generator for training\n",
        "    train_data_generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255, \n",
        "        shear_range=0.2, \n",
        "        zoom_range=0.2, \n",
        "        horizontal_flip=True)\n",
        "    # Create a data generator for validation\n",
        "    validation_data_generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2, \n",
        "        horizontal_flip=True)\n",
        "    # Create a train generator\n",
        "    train_generator = train_data_generator.flow_from_directory( \n",
        "        '/content/drive/MyDrive/prepro/clahee/train', \n",
        "        target_size=(img_width, img_height), \n",
        "        batch_size=batch_size,\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        class_mode='categorical')\n",
        "    # Create a test generator\n",
        "    validation_generator = validation_data_generator.flow_from_directory( \n",
        "        '/content/drive/MyDrive/prepro/clahee/test', \n",
        "        target_size=(img_width, img_height), \n",
        "        batch_size=batch_size,\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        class_mode='categorical')\n",
        "    # Start training, fit the model\n",
        "    history=model.fit_generator( \n",
        "        train_generator, \n",
        "        steps_per_epoch=train_samples // batch_size, \n",
        "        validation_data=validation_generator, \n",
        "        validation_steps=validation_samples // batch_size,\n",
        "        epochs=epochs)\n",
        "    # Save model to disk\n",
        "    model.save('/content/drive/MyDrive/resnet_50.h5')\n",
        "    print('Saved model to disk!')\n",
        "    # Get labels\n",
        "    labels = train_generator.class_indices\n",
        "    # Invert labels\n",
        "    classes = {}\n",
        "    for key, value in labels.items():\n",
        "        classes[value] = key.capitalize()\n",
        "    # Save classes to file\n",
        "    with open('/content/drive/MyDrive/classes.pkl', 'wb') as file:\n",
        "        pickle.dump(classes, file)\n",
        "    print('Saved classes to disk!')"
      ],
      "metadata": {
        "id": "DmUScfohJDsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The main entry point for this module\n",
        "def main():\n",
        "    # Train a model\n",
        "    train()\n",
        "# Tell python to run main method\n",
        "if __name__ == '__main__': main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YEq1pTcJLmk",
        "outputId": "23bf4b73-93df-4101-bc1c-2b9f1c82730d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 49 images belonging to 2 classes.\n",
            "Found 31 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3/3 [==============================] - 14s 5s/step - loss: 0.1568 - accuracy: 0.8571 - val_loss: 0.6815 - val_accuracy: 0.7778\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.1033 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.8889\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.5424 - val_accuracy: 0.6667\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.7420 - val_accuracy: 0.7778\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.2613 - accuracy: 0.8889 - val_loss: 1.8648 - val_accuracy: 0.5556\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 1.9234 - val_accuracy: 0.3333\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5718 - val_accuracy: 0.7778\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.6667\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 1.3699 - val_accuracy: 0.5556\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.8889\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 1.0524 - val_accuracy: 0.5556\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.6667\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.6158 - val_accuracy: 0.7778\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.1536 - accuracy: 0.8571 - val_loss: 1.2532 - val_accuracy: 0.4444\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.2573 - accuracy: 0.7778 - val_loss: 1.8601 - val_accuracy: 0.4444\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.6178 - val_accuracy: 0.6667\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0927 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.8889\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.6204 - val_accuracy: 0.5556\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.1728 - accuracy: 1.0000 - val_loss: 1.2070 - val_accuracy: 0.5556\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.6667\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 1.1135 - val_accuracy: 0.4444\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.2448 - accuracy: 0.7143 - val_loss: 0.8799 - val_accuracy: 0.6667\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.7778\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0854 - accuracy: 0.8889 - val_loss: 0.1450 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.2381 - accuracy: 0.8889 - val_loss: 1.1533 - val_accuracy: 0.5556\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.8034 - val_accuracy: 0.7778\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.1012 - accuracy: 1.0000 - val_loss: 0.9813 - val_accuracy: 0.5556\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.6667\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.1591 - accuracy: 0.8889 - val_loss: 0.5591 - val_accuracy: 0.6667\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.8464 - val_accuracy: 0.6667\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.8140 - val_accuracy: 0.7778\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.8889\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.7778\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.7778\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.8889\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.7778\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.6057 - val_accuracy: 0.6667\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5332 - val_accuracy: 0.7778\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.1076 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.8889\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.6667\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 9.8949e-04 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.8990 - val_accuracy: 0.6667\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.8889\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.7778\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.8889\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.8889\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.8889\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.8889\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.7778\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.8889\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.7778\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.7778\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.1199 - accuracy: 0.8571 - val_loss: 0.4180 - val_accuracy: 0.8889\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.8889\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 1.0833 - val_accuracy: 0.5556\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.7778\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.6667\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.5995 - val_accuracy: 0.6667\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.6633 - val_accuracy: 0.7778\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.8927 - val_accuracy: 0.5556\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.1047 - accuracy: 0.8889 - val_loss: 0.0641 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.8889\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.6498 - val_accuracy: 0.6667\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.8889\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.2027 - accuracy: 0.8889 - val_loss: 0.9604 - val_accuracy: 0.6667\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.8889\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.6115 - val_accuracy: 0.7778\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.6667\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.6371 - val_accuracy: 0.5556\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.5556\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.8889\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.7778\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.2309 - accuracy: 0.8889 - val_loss: 0.3034 - val_accuracy: 0.8889\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1552 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.7778\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.8889\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.6667\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.7778\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 1.2291 - val_accuracy: 0.6667\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.6667\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0875 - accuracy: 0.8889 - val_loss: 0.0798 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.5061 - val_accuracy: 0.6667\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.8889\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.4846 - accuracy: 0.8889 - val_loss: 0.1499 - val_accuracy: 0.8889\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.8889\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.8889\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.8889\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.0929 - val_accuracy: 0.5556\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.3017 - accuracy: 0.7778 - val_loss: 0.6912 - val_accuracy: 0.7778\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.8889\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 1.4882 - val_accuracy: 0.5556\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0871 - accuracy: 0.8889 - val_loss: 0.2188 - val_accuracy: 0.8889\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.7778\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.1004 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.1804 - accuracy: 0.8889 - val_loss: 0.6207 - val_accuracy: 0.7778\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.7778\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.5556\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.9629 - val_accuracy: 0.5556\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 2.0181 - val_accuracy: 0.4444\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.2624 - accuracy: 0.8571 - val_loss: 0.7838 - val_accuracy: 0.7778\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.7778\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.8889\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.8889\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.7778\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.7778\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.7778\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.1362 - accuracy: 0.8889 - val_loss: 0.7030 - val_accuracy: 0.6667\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.8889\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.4938 - val_accuracy: 0.7778\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.6745 - val_accuracy: 0.8889\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.7778\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.9402 - val_accuracy: 0.6667\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.7778\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.6667\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.1483 - accuracy: 0.8889 - val_loss: 0.5005 - val_accuracy: 0.7778\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.5687 - val_accuracy: 0.7778\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.1440 - accuracy: 0.8889 - val_loss: 0.4586 - val_accuracy: 0.6667\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.8889\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.8889\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.7778\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.6667\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.8889\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.3883 - val_accuracy: 0.8889\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.7778\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.1792 - accuracy: 0.8889 - val_loss: 0.4269 - val_accuracy: 0.7778\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.6667\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 0.8889\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.8889\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 8s 2s/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.8889\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.8889\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.7778\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.6468 - accuracy: 0.8889 - val_loss: 0.9827 - val_accuracy: 0.7778\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.5119 - accuracy: 0.8889 - val_loss: 0.0847 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.8889\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.2028 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.8889\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 1.1341 - val_accuracy: 0.6667\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.8889\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.6024 - val_accuracy: 0.6667\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.6767 - val_accuracy: 0.6667\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.5567 - val_accuracy: 0.7778\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.0764 - val_accuracy: 0.6667\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.6667\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 1.1913 - val_accuracy: 0.7778\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0857 - accuracy: 0.8889 - val_loss: 0.2757 - val_accuracy: 0.8889\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.8889\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.8889\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0895 - accuracy: 0.8889 - val_loss: 0.1359 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 4.3648e-04 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.8889\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4099 - val_accuracy: 0.7778\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.6491 - val_accuracy: 0.8889\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.8889\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.7313 - val_accuracy: 0.7778\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 9s 4s/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.8889\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.7519 - val_accuracy: 0.6667\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 1.0427 - val_accuracy: 0.5556\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.5309 - val_accuracy: 0.7778\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.8889\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.8889\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.8889\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5766 - val_accuracy: 0.7778\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.7778\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 1.2084 - val_accuracy: 0.5556\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 1.3996 - val_accuracy: 0.5556\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.8889\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.1425 - val_accuracy: 0.6667\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.7778\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.6667\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 10s 4s/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.8889\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.8889\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.8889\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.7778\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7609 - val_accuracy: 0.7778\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 7s 3s/step - loss: 0.2336 - accuracy: 0.8571 - val_loss: 0.8177 - val_accuracy: 0.6667\n",
            "Saved model to disk!\n",
            "Saved classes to disk!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn import metrics\n",
        "\n",
        "actual = numpy.random.binomial(1,.9,size = 1000)\n",
        "predicted = numpy.random.binomial(1,.9,size = 1000)\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NNq6H8pQSTM7",
        "outputId": "d8a690b2-2668-4db8-9448-b8e719081310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}