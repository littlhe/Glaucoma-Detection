{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inceptionV3main300.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzDZfWVXNNn_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z07P9rEbxuqd"
      },
      "outputs": [],
      "source": [
        "class LogisticEndpoint(keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super(LogisticEndpoint, self).__init__(name=name)\n",
        "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
        "\n",
        "    def call(self, targets, logits, sample_weights=None):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        loss = self.loss_fn(targets, logits, sample_weights)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # Log accuracy as a metric and add it\n",
        "        # to the layer using `self.add_metric()`.\n",
        "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
        "        self.add_metric(acc, name=\"accuracy\")\n",
        "\n",
        "        # Return the inference-time prediction tensor (for `.predict()`).\n",
        "        return tf.nn.softmax(logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzr9Q9lMx51I"
      },
      "outputs": [],
      "source": [
        "layer = LogisticEndpoint()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2lbo3GLx9Vh"
      },
      "outputs": [],
      "source": [
        "targets = tf.ones((2, 2))\n",
        "logits = tf.ones((2, 2))\n",
        "y = layer(targets, logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2eo0XqTyDsx",
        "outputId": "30b1df6e-34b3-4872-cca7-4f63c5df6ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer.metrics: [<keras.metrics.BinaryAccuracy object at 0x7f5b81201210>]\n",
            "current accuracy value: 1.0\n"
          ]
        }
      ],
      "source": [
        "print(\"layer.metrics:\", layer.metrics)\n",
        "print(\"current accuracy value:\", float(layer.metrics[0].result()))\n",
        "inputs = keras.Input(shape=(3,), name=\"inputs\")\n",
        "targets = keras.Input(shape=(10,), name=\"targets\")\n",
        "logits = keras.layers.Dense(10)(inputs)\n",
        "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlUZ43L2yHDP"
      },
      "outputs": [],
      "source": [
        "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
        "model.compile(optimizer=\"adam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TkPkyEtyJgL",
        "outputId": "1f905151-b3fb-4d45-b6b5-721b1eb5c730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 515ms/step - loss: 0.9407 - binary_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5b0700af10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data = {\n",
        "    \"inputs\": np.random.random((3, 3)),\n",
        "    \"targets\": np.random.random((3, 10)),\n",
        "}\n",
        "model.fit(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EQW0wl-yQfG"
      },
      "outputs": [],
      "source": [
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "#from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "#from keras.models import Model\n",
        "#from keras.layers import Input\n",
        "#from keras.layers import Conv2D\n",
        "#from keras.layers import MaxPooling2D\n",
        "#from keras.layers.merge import concatenate\n",
        "#from keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvFOO8TjyT8g"
      },
      "outputs": [],
      "source": [
        "#inception naive version\n",
        "\n",
        "def inception_module(x, f1, f2, f3):\n",
        "\t# 1x1 conv\n",
        "\tconv1 =  keras.layers.Conv2D(f1, (1,1), padding='same', activation='relu')(x)\n",
        "\t# 3x3 conv\n",
        "\tconv3 = keras.layers.Conv2D(f2, (3,3), padding='same', activation='relu')(x)\n",
        "\t# 5x5 conv\n",
        "\tconv5 = keras.layers.Conv2D(f3, (5,5), padding='same', activation='relu')(x)\n",
        "\t# 3x3 max pooling\n",
        "\tpool = keras.layers.MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n",
        "\t# concatenate filters\n",
        "\tout = keras.layers.merge.concatenate([conv1, conv3, conv5, pool])\n",
        "\treturn out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-vgU_jAyXNK"
      },
      "outputs": [],
      "source": [
        "img_input = keras.Input(shape=(299, 299, 3))\n",
        "classes=2\n",
        "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "WEIGHTS_PATH = 'inception_v3_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "WEIGHTS_PATH = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "channel_axis=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOIzJrlXyZna"
      },
      "outputs": [],
      "source": [
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkLMFedSycZu",
        "outputId": "fa2167f6-b081-42e3-ee3f-50216a9277c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 49 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Drishti Vgg16/prepro/clahee/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 7,\n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WRNgn8nfbP5",
        "outputId": "14b4b128-3a87-43ac-bb25-228254c1cc4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Drishti Vgg16/prepro/clahee/test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 5,\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sTzjsYMfpjv"
      },
      "outputs": [],
      "source": [
        "def conv2d_bn(x,filters,num_row,num_col,padding='same',strides=(1, 1)):\n",
        "   \n",
        "    x = keras.layers.Conv2D(filters, (num_row, num_col),strides=strides,padding=padding)(x)\n",
        "    x = keras.layers.BatchNormalization(axis=3, scale=False)(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vf4msvAfvtW"
      },
      "outputs": [],
      "source": [
        "def inc_block_a(x):    \n",
        "    branch1x1 = conv2d_bn(x, 64, 1, 1)  # 64 filters of 1*1\n",
        "\n",
        "    branch5x5 = conv2d_bn(x, 48, 1, 1)  #48 filters of 1*1\n",
        "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "    x = keras.layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool], axis=channel_axis)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QLNN-12g_hx"
      },
      "outputs": [],
      "source": [
        "def reduction_block_a(x):  \n",
        "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_pool = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    x = keras.layers.concatenate([branch3x3, branch3x3dbl, branch_pool],axis=channel_axis)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkKtxfR7hCiG"
      },
      "outputs": [],
      "source": [
        "# 17 x 17 x 768\n",
        "def inc_block_b(x):\n",
        "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "    branch_pool = keras.layers.AveragePooling2D((3, 3), strides=(1, 1),padding='same')(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "    x = keras.layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool], axis=channel_axis)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT5Fnnh4hFi_"
      },
      "outputs": [],
      "source": [
        "# mixed 8: 8 x 8 x 1280\n",
        "def reduction_block_b(x): \n",
        "    branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
        "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
        "    branch7x7x3 = conv2d_bn( branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_pool = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    x = keras.layers.concatenate([branch3x3, branch7x7x3, branch_pool], axis=channel_axis)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI0SUEaIjbXV"
      },
      "outputs": [],
      "source": [
        "def inc_block_c(x):        \n",
        "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
        "\n",
        "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
        "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
        "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
        "        branch3x3 = keras.layers.concatenate([branch3x3_1, branch3x3_2],axis=channel_axis)\n",
        "\n",
        "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
        "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
        "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
        "        branch3x3dbl = keras.layers.concatenate([branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n",
        "\n",
        "        branch_pool = keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "        x = keras.layers.concatenate( [branch1x1, branch3x3, branch3x3dbl, branch_pool],axis=channel_axis)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XTlGo4cjhO6"
      },
      "outputs": [],
      "source": [
        "img_input = keras.Input(shape=(299, 299, 3))  #shape=(None, 299, 299, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyzz1WY6ji7f",
        "outputId": "4e431a18-9e2e-4d68-fba9-79237f3d453e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 149, 149, 32  896         ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 147, 147, 32  9248        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 147, 147, 64  18496       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5200        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138432      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12352       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9264        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55392       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12352       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76864       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 35, 35, 96)   83040       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6176        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16448       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12336       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55392       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['concatenate[0][0]']            \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16448       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76864       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 35, 35, 96)   83040       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 35, 35, 32)   8224        ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 35, 35, 32)  96          ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 35, 35, 256)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 35, 35, 64)   16448       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 35, 35, 48)   12336       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55392       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 35, 35, 256)  0          ['concatenate_1[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 35, 35, 64)   16448       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76864       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 35, 35, 96)   83040       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 35, 35, 32)   8224        ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 35, 35, 32)  96          ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 35, 35, 256)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 35, 35, 64)   16448       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55392       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 17, 17, 384)  885120      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 17, 17, 96)   83040       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 256)  0          ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 17, 17, 736)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 17, 17, 128)  94336       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 17, 17, 128)  94336       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 17, 17, 736)  0          ['concatenate_3[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 17, 17, 192)  141504      ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 17, 17, 192)  141504      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 17, 17, 128)  98432       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 17, 17, 128)  384        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 17, 17, 128)  384        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 17, 17, 128)  98432       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 17, 17, 128)  384        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 17, 17, 128)  384        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 17, 17, 128)  384        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 17, 17, 128)  384        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['concatenate_4[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147648      ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147648      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 17, 17, 128)  98432       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 17, 17, 128)  384        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 17, 17, 128)  384        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 17, 17, 128)  98432       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 17, 17, 128)  384        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 17, 17, 128)  384        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 17, 17, 128)  384        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 17, 17, 128)  384        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['concatenate_5[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147648      ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147648      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 17, 17, 128)  98432       ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 17, 17, 128)  384        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 17, 17, 128)  384        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 17, 17, 128)  98432       ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 17, 17, 128)  384        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 17, 17, 128)  384        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 17, 17, 128)  384        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 17, 17, 128)  384        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['concatenate_6[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147648      ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147648      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147648      ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258240      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147648      ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258240      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 8, 8, 320)    553280      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331968      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573888      ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491904      ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548672     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['concatenate_8[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409920      ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245952      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'concatenate_9[0][0]',          \n",
            "                                                                  'concatenate_10[0][0]',         \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917952      ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786816      ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548672     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['concatenate_11[0][0]']         \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655680      ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393408      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'concatenate_12[0][0]',         \n",
            "                                                                  'concatenate_13[0][0]',         \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['concatenate_14[0][0]']         \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " predictions (Dense)            (None, 2)            4098        ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,033,378\n",
            "Trainable params: 20,000,610\n",
            "Non-trainable params: 32,768\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# input image size: 299 x 299 x 3\n",
        "x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid') # 149 x 149 x 32\n",
        "x = conv2d_bn(x, 32, 3, 3, padding='valid')  # 147 x 147 x 32\n",
        "x = conv2d_bn(x, 64, 3, 3) # 147 x 147 x 64\n",
        "\n",
        "x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)   # 73  x 73 x 64\n",
        "x = conv2d_bn(x, 80, 1, 1, padding='valid') # 73 x 73 x 80\n",
        "x = conv2d_bn(x, 192, 3, 3, padding='valid')  # 71 x 71 x 192\n",
        "x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)  # 35 x 35 x 192\n",
        "\n",
        "\n",
        "x=inc_block_a(x) #35, 35, 256\n",
        "x=inc_block_a(x) #35, 35, 256\n",
        "x=inc_block_a(x) #35, 35, 256\n",
        "\n",
        "x=reduction_block_a(x) #17, 17, 736\n",
        "\n",
        "x=inc_block_b(x) #17, 17, 768\n",
        "x=inc_block_b(x) #17, 17, 768\n",
        "x=inc_block_b(x) #17, 17, 768\n",
        "x=inc_block_b(x) #17, 17, 768\n",
        "\n",
        "x=reduction_block_b(x) #shape=(None, 8, 8, 1280)\n",
        "\n",
        "x=inc_block_c(x) # shape=(None, 8, 8, 2048) \n",
        "x=inc_block_c(x) # shape=(None, 8, 8, 2048) \n",
        "\n",
        "x = keras.layers.GlobalAveragePooling2D(name='avg_pool')(x) # shape=(None, 2048)\n",
        "\n",
        "x = keras.layers.Dense(classes, activation='softmax', name='predictions')(x) #shape=(None, 1000) \n",
        "\n",
        "\n",
        "\n",
        "# Create model.\n",
        "inputs = img_input\n",
        "model =  keras.Model(inputs, x, name='inception_v3')\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHEZxNYUjpkS"
      },
      "outputs": [],
      "source": [
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_60q_nAjr3R",
        "outputId": "84073fa6-9d51-472d-e412-f94723ff6ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "7/7 [==============================] - 39s 5s/step - loss: 2.0304 - accuracy: 0.5918 - val_loss: 0.7929 - val_accuracy: 0.2581\n",
            "Epoch 2/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.9768 - accuracy: 0.6122 - val_loss: 0.5852 - val_accuracy: 0.7419\n",
            "Epoch 3/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.8814 - accuracy: 0.5510 - val_loss: 0.8479 - val_accuracy: 0.2581\n",
            "Epoch 4/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.5854 - accuracy: 0.6531 - val_loss: 0.7099 - val_accuracy: 0.2581\n",
            "Epoch 5/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.6958 - accuracy: 0.6327 - val_loss: 0.8458 - val_accuracy: 0.2581\n",
            "Epoch 6/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.6772 - accuracy: 0.6939 - val_loss: 1.0328 - val_accuracy: 0.2581\n",
            "Epoch 7/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.7196 - accuracy: 0.6327 - val_loss: 0.7118 - val_accuracy: 0.2581\n",
            "Epoch 8/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.5751 - accuracy: 0.7143 - val_loss: 0.9684 - val_accuracy: 0.2581\n",
            "Epoch 9/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.5753 - accuracy: 0.6531 - val_loss: 1.0965 - val_accuracy: 0.2581\n",
            "Epoch 10/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.4615 - accuracy: 0.8367 - val_loss: 0.8986 - val_accuracy: 0.2581\n",
            "Epoch 11/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.5174 - accuracy: 0.7755 - val_loss: 0.7204 - val_accuracy: 0.2581\n",
            "Epoch 12/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.6723 - accuracy: 0.7143 - val_loss: 0.8634 - val_accuracy: 0.2581\n",
            "Epoch 13/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.5952 - accuracy: 0.6735 - val_loss: 0.6192 - val_accuracy: 0.7419\n",
            "Epoch 14/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.5812 - accuracy: 0.6939 - val_loss: 0.7699 - val_accuracy: 0.2581\n",
            "Epoch 15/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.4880 - accuracy: 0.7551 - val_loss: 0.9720 - val_accuracy: 0.2581\n",
            "Epoch 16/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.2940 - accuracy: 0.8980 - val_loss: 1.4654 - val_accuracy: 0.2581\n",
            "Epoch 17/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.6849 - accuracy: 0.7143 - val_loss: 1.1284 - val_accuracy: 0.2581\n",
            "Epoch 18/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.4479 - accuracy: 0.8367 - val_loss: 1.0351 - val_accuracy: 0.2581\n",
            "Epoch 19/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.4406 - accuracy: 0.7755 - val_loss: 0.5628 - val_accuracy: 0.7419\n",
            "Epoch 20/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.3325 - accuracy: 0.8776 - val_loss: 0.7496 - val_accuracy: 0.7419\n",
            "Epoch 21/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.6195 - accuracy: 0.7959 - val_loss: 0.6432 - val_accuracy: 0.6774\n",
            "Epoch 22/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.5796 - accuracy: 0.7755 - val_loss: 0.5524 - val_accuracy: 0.7419\n",
            "Epoch 23/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.4256 - accuracy: 0.7959 - val_loss: 0.4923 - val_accuracy: 0.7742\n",
            "Epoch 24/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.4486 - accuracy: 0.7755 - val_loss: 0.5496 - val_accuracy: 0.7419\n",
            "Epoch 25/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.3981 - accuracy: 0.8571 - val_loss: 0.6597 - val_accuracy: 0.5806\n",
            "Epoch 26/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.3805 - accuracy: 0.8367 - val_loss: 1.4896 - val_accuracy: 0.3226\n",
            "Epoch 27/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2676 - accuracy: 0.8776 - val_loss: 2.3886 - val_accuracy: 0.2581\n",
            "Epoch 28/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2842 - accuracy: 0.8776 - val_loss: 0.6136 - val_accuracy: 0.6774\n",
            "Epoch 29/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2510 - accuracy: 0.8980 - val_loss: 4.8824 - val_accuracy: 0.3226\n",
            "Epoch 30/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2907 - accuracy: 0.8980 - val_loss: 7.9898 - val_accuracy: 0.2581\n",
            "Epoch 31/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2270 - accuracy: 0.9184 - val_loss: 2.9591 - val_accuracy: 0.3226\n",
            "Epoch 32/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.3087 - accuracy: 0.8776 - val_loss: 2.8544 - val_accuracy: 0.2903\n",
            "Epoch 33/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.3765 - accuracy: 0.8776 - val_loss: 1.1666 - val_accuracy: 0.4194\n",
            "Epoch 34/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2719 - accuracy: 0.8776 - val_loss: 0.5553 - val_accuracy: 0.7419\n",
            "Epoch 35/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1737 - accuracy: 0.9184 - val_loss: 0.5937 - val_accuracy: 0.7419\n",
            "Epoch 36/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.3612 - accuracy: 0.8571 - val_loss: 3.4026 - val_accuracy: 0.2581\n",
            "Epoch 37/300\n",
            "7/7 [==============================] - 24s 3s/step - loss: 0.6601 - accuracy: 0.7959 - val_loss: 3.4383 - val_accuracy: 0.2581\n",
            "Epoch 38/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2329 - accuracy: 0.9388 - val_loss: 0.7593 - val_accuracy: 0.6129\n",
            "Epoch 39/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1889 - accuracy: 0.9184 - val_loss: 2.5101 - val_accuracy: 0.2581\n",
            "Epoch 40/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1793 - accuracy: 0.9388 - val_loss: 4.6332 - val_accuracy: 0.2581\n",
            "Epoch 41/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0876 - accuracy: 0.9592 - val_loss: 5.1416 - val_accuracy: 0.2581\n",
            "Epoch 42/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1711 - accuracy: 0.9592 - val_loss: 5.3438 - val_accuracy: 0.2581\n",
            "Epoch 43/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.4214 - accuracy: 0.8367 - val_loss: 1.5291 - val_accuracy: 0.4194\n",
            "Epoch 44/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.3348 - accuracy: 0.8367 - val_loss: 0.8045 - val_accuracy: 0.7419\n",
            "Epoch 45/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.3457 - accuracy: 0.8163 - val_loss: 0.5165 - val_accuracy: 0.6774\n",
            "Epoch 46/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.4047 - accuracy: 0.8776 - val_loss: 1.1376 - val_accuracy: 0.7419\n",
            "Epoch 47/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1643 - accuracy: 0.9592 - val_loss: 24.8485 - val_accuracy: 0.7419\n",
            "Epoch 48/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2278 - accuracy: 0.9184 - val_loss: 21.8384 - val_accuracy: 0.7097\n",
            "Epoch 49/300\n",
            "7/7 [==============================] - 24s 3s/step - loss: 0.1140 - accuracy: 0.9796 - val_loss: 16.8946 - val_accuracy: 0.7097\n",
            "Epoch 50/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.3939 - accuracy: 0.8980 - val_loss: 25.4378 - val_accuracy: 0.7419\n",
            "Epoch 51/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2755 - accuracy: 0.8776 - val_loss: 19.2957 - val_accuracy: 0.7419\n",
            "Epoch 52/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2924 - accuracy: 0.8776 - val_loss: 3.7485 - val_accuracy: 0.7097\n",
            "Epoch 53/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2139 - accuracy: 0.8571 - val_loss: 1.2337 - val_accuracy: 0.6452\n",
            "Epoch 54/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2301 - accuracy: 0.8776 - val_loss: 2.8150 - val_accuracy: 0.4839\n",
            "Epoch 55/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2067 - accuracy: 0.9184 - val_loss: 6.4952 - val_accuracy: 0.3226\n",
            "Epoch 56/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.3026 - accuracy: 0.8571 - val_loss: 1.0699 - val_accuracy: 0.6129\n",
            "Epoch 57/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.4522 - accuracy: 0.8163 - val_loss: 0.3852 - val_accuracy: 0.8710\n",
            "Epoch 58/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.2875 - accuracy: 0.8980 - val_loss: 0.6548 - val_accuracy: 0.7742\n",
            "Epoch 59/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2097 - accuracy: 0.8980 - val_loss: 2.0725 - val_accuracy: 0.5161\n",
            "Epoch 60/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1580 - accuracy: 0.9592 - val_loss: 2.7362 - val_accuracy: 0.4516\n",
            "Epoch 61/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.3483 - accuracy: 0.8776 - val_loss: 1.8190 - val_accuracy: 0.5806\n",
            "Epoch 62/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0823 - accuracy: 0.9796 - val_loss: 1.1052 - val_accuracy: 0.6129\n",
            "Epoch 63/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2224 - accuracy: 0.9388 - val_loss: 1.2746 - val_accuracy: 0.6774\n",
            "Epoch 64/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.3612 - accuracy: 0.8776 - val_loss: 0.8742 - val_accuracy: 0.6452\n",
            "Epoch 65/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1467 - accuracy: 0.9388 - val_loss: 0.8059 - val_accuracy: 0.7097\n",
            "Epoch 66/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0915 - accuracy: 0.9592 - val_loss: 0.6170 - val_accuracy: 0.8065\n",
            "Epoch 67/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0807 - accuracy: 0.9796 - val_loss: 0.8986 - val_accuracy: 0.7419\n",
            "Epoch 68/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1137 - accuracy: 0.9184 - val_loss: 1.1422 - val_accuracy: 0.7742\n",
            "Epoch 69/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1105 - accuracy: 0.9796 - val_loss: 0.6873 - val_accuracy: 0.8387\n",
            "Epoch 70/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0797 - accuracy: 0.9796 - val_loss: 0.8547 - val_accuracy: 0.8065\n",
            "Epoch 71/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1182 - accuracy: 0.9388 - val_loss: 1.2842 - val_accuracy: 0.7419\n",
            "Epoch 72/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1142 - accuracy: 0.9592 - val_loss: 0.9780 - val_accuracy: 0.8065\n",
            "Epoch 73/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1440 - accuracy: 0.9592 - val_loss: 1.4905 - val_accuracy: 0.8387\n",
            "Epoch 74/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2711 - accuracy: 0.9388 - val_loss: 0.9499 - val_accuracy: 0.6774\n",
            "Epoch 75/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1329 - accuracy: 0.9388 - val_loss: 0.8661 - val_accuracy: 0.7419\n",
            "Epoch 76/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1860 - accuracy: 0.9592 - val_loss: 0.3733 - val_accuracy: 0.8710\n",
            "Epoch 77/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0837 - accuracy: 0.9592 - val_loss: 0.4680 - val_accuracy: 0.8387\n",
            "Epoch 78/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.3722 - accuracy: 0.8571 - val_loss: 0.5585 - val_accuracy: 0.8065\n",
            "Epoch 79/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2713 - accuracy: 0.8776 - val_loss: 1.2941 - val_accuracy: 0.7419\n",
            "Epoch 80/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2079 - accuracy: 0.8776 - val_loss: 0.9079 - val_accuracy: 0.7097\n",
            "Epoch 81/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1185 - accuracy: 0.9592 - val_loss: 1.7129 - val_accuracy: 0.7419\n",
            "Epoch 82/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1668 - accuracy: 0.8980 - val_loss: 2.3117 - val_accuracy: 0.7419\n",
            "Epoch 83/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1564 - accuracy: 0.9388 - val_loss: 3.1021 - val_accuracy: 0.7742\n",
            "Epoch 84/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1169 - accuracy: 0.9388 - val_loss: 3.1659 - val_accuracy: 0.7419\n",
            "Epoch 85/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0469 - accuracy: 0.9796 - val_loss: 2.3313 - val_accuracy: 0.7419\n",
            "Epoch 86/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.8300 - val_accuracy: 0.7742\n",
            "Epoch 87/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0670 - accuracy: 0.9796 - val_loss: 1.7055 - val_accuracy: 0.7742\n",
            "Epoch 88/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0434 - accuracy: 0.9796 - val_loss: 2.5192 - val_accuracy: 0.7742\n",
            "Epoch 89/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.7269 - val_accuracy: 0.7742\n",
            "Epoch 90/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0409 - accuracy: 0.9796 - val_loss: 2.4722 - val_accuracy: 0.7742\n",
            "Epoch 91/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0370 - accuracy: 0.9796 - val_loss: 2.2511 - val_accuracy: 0.7419\n",
            "Epoch 92/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.7340 - val_accuracy: 0.8065\n",
            "Epoch 93/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 1.1932 - val_accuracy: 0.8065\n",
            "Epoch 94/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0668 - accuracy: 0.9796 - val_loss: 1.8330 - val_accuracy: 0.8065\n",
            "Epoch 95/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0712 - accuracy: 0.9796 - val_loss: 1.8578 - val_accuracy: 0.5806\n",
            "Epoch 96/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.3043 - accuracy: 0.9184 - val_loss: 1.4351 - val_accuracy: 0.5484\n",
            "Epoch 97/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.5983 - accuracy: 0.8776 - val_loss: 5.9350 - val_accuracy: 0.7097\n",
            "Epoch 98/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.3076 - accuracy: 0.8367 - val_loss: 3.9864 - val_accuracy: 0.7742\n",
            "Epoch 99/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2225 - accuracy: 0.9184 - val_loss: 0.6694 - val_accuracy: 0.8065\n",
            "Epoch 100/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.2256 - accuracy: 0.9184 - val_loss: 1.7390 - val_accuracy: 0.8387\n",
            "Epoch 101/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1902 - accuracy: 0.9388 - val_loss: 1.6470 - val_accuracy: 0.8065\n",
            "Epoch 102/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1555 - accuracy: 0.9388 - val_loss: 2.5823 - val_accuracy: 0.8065\n",
            "Epoch 103/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1735 - accuracy: 0.8980 - val_loss: 3.4218 - val_accuracy: 0.7419\n",
            "Epoch 104/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0910 - accuracy: 0.9388 - val_loss: 2.2019 - val_accuracy: 0.7419\n",
            "Epoch 105/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2290 - accuracy: 0.8776 - val_loss: 5.9258 - val_accuracy: 0.7742\n",
            "Epoch 106/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1226 - accuracy: 0.9184 - val_loss: 13.4707 - val_accuracy: 0.7419\n",
            "Epoch 107/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0584 - accuracy: 0.9796 - val_loss: 8.9741 - val_accuracy: 0.8065\n",
            "Epoch 108/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1743 - accuracy: 0.9796 - val_loss: 4.9577 - val_accuracy: 0.8387\n",
            "Epoch 109/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2769 - accuracy: 0.8980 - val_loss: 4.0105 - val_accuracy: 0.8710\n",
            "Epoch 110/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.2140 - accuracy: 0.9388 - val_loss: 0.8970 - val_accuracy: 0.8065\n",
            "Epoch 111/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1873 - accuracy: 0.9592 - val_loss: 1.4129 - val_accuracy: 0.7097\n",
            "Epoch 112/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.3425 - accuracy: 0.8776 - val_loss: 11.3760 - val_accuracy: 0.7742\n",
            "Epoch 113/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.2193 - accuracy: 0.9388 - val_loss: 2.3265 - val_accuracy: 0.7419\n",
            "Epoch 114/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.4965 - accuracy: 0.8571 - val_loss: 24.0626 - val_accuracy: 0.2581\n",
            "Epoch 115/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1939 - accuracy: 0.9184 - val_loss: 12.4194 - val_accuracy: 0.2903\n",
            "Epoch 116/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.3674 - accuracy: 0.8980 - val_loss: 2.3879 - val_accuracy: 0.7097\n",
            "Epoch 117/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.3021 - accuracy: 0.8776 - val_loss: 10.8521 - val_accuracy: 0.3226\n",
            "Epoch 118/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1269 - accuracy: 0.9796 - val_loss: 2.1036 - val_accuracy: 0.5484\n",
            "Epoch 119/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1013 - accuracy: 0.9796 - val_loss: 3.1545 - val_accuracy: 0.7742\n",
            "Epoch 120/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 2.8859 - val_accuracy: 0.7419\n",
            "Epoch 121/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1292 - accuracy: 0.9592 - val_loss: 3.4779 - val_accuracy: 0.7419\n",
            "Epoch 122/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0992 - accuracy: 0.9592 - val_loss: 2.2088 - val_accuracy: 0.7742\n",
            "Epoch 123/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2161 - accuracy: 0.9184 - val_loss: 1.9223 - val_accuracy: 0.8065\n",
            "Epoch 124/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1477 - accuracy: 0.9388 - val_loss: 1.2327 - val_accuracy: 0.7742\n",
            "Epoch 125/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.2176 - accuracy: 0.9184 - val_loss: 1.0327 - val_accuracy: 0.8065\n",
            "Epoch 126/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2138 - accuracy: 0.9184 - val_loss: 3.8452 - val_accuracy: 0.7419\n",
            "Epoch 127/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.3946 - accuracy: 0.8980 - val_loss: 2.7827 - val_accuracy: 0.7419\n",
            "Epoch 128/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.4235 - accuracy: 0.8367 - val_loss: 2.2741 - val_accuracy: 0.7419\n",
            "Epoch 129/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2420 - accuracy: 0.8980 - val_loss: 4.1060 - val_accuracy: 0.7419\n",
            "Epoch 130/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0933 - accuracy: 0.9388 - val_loss: 3.8057 - val_accuracy: 0.7419\n",
            "Epoch 131/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0525 - accuracy: 0.9796 - val_loss: 2.9460 - val_accuracy: 0.7419\n",
            "Epoch 132/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.2095 - accuracy: 0.8980 - val_loss: 2.4631 - val_accuracy: 0.7419\n",
            "Epoch 133/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1036 - accuracy: 0.9592 - val_loss: 2.3698 - val_accuracy: 0.7419\n",
            "Epoch 134/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1823 - accuracy: 0.9184 - val_loss: 2.2557 - val_accuracy: 0.7419\n",
            "Epoch 135/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 2.6912 - val_accuracy: 0.7419\n",
            "Epoch 136/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 4.7331 - val_accuracy: 0.7419\n",
            "Epoch 137/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0613 - accuracy: 0.9796 - val_loss: 3.4208 - val_accuracy: 0.7419\n",
            "Epoch 138/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 2.4148 - val_accuracy: 0.7419\n",
            "Epoch 139/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.7016 - val_accuracy: 0.7742\n",
            "Epoch 140/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0899 - accuracy: 0.9592 - val_loss: 2.8202 - val_accuracy: 0.7419\n",
            "Epoch 141/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0401 - accuracy: 0.9796 - val_loss: 3.1244 - val_accuracy: 0.7419\n",
            "Epoch 142/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1640 - accuracy: 0.9592 - val_loss: 1.8115 - val_accuracy: 0.8065\n",
            "Epoch 143/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0820 - accuracy: 0.9388 - val_loss: 0.6656 - val_accuracy: 0.8065\n",
            "Epoch 144/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0471 - accuracy: 0.9796 - val_loss: 0.7613 - val_accuracy: 0.7419\n",
            "Epoch 145/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0919 - accuracy: 0.9592 - val_loss: 1.9069 - val_accuracy: 0.5484\n",
            "Epoch 146/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1746 - accuracy: 0.9184 - val_loss: 3.8468 - val_accuracy: 0.7419\n",
            "Epoch 147/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1029 - accuracy: 0.9388 - val_loss: 3.0032 - val_accuracy: 0.7097\n",
            "Epoch 148/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.2666 - val_accuracy: 0.7097\n",
            "Epoch 149/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1476 - accuracy: 0.9592 - val_loss: 2.5136 - val_accuracy: 0.7419\n",
            "Epoch 150/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1231 - accuracy: 0.9388 - val_loss: 3.3482 - val_accuracy: 0.7097\n",
            "Epoch 151/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.2006 - accuracy: 0.9388 - val_loss: 2.8694 - val_accuracy: 0.6452\n",
            "Epoch 152/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1565 - accuracy: 0.9388 - val_loss: 0.7677 - val_accuracy: 0.7097\n",
            "Epoch 153/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0737 - accuracy: 0.9796 - val_loss: 0.7449 - val_accuracy: 0.8387\n",
            "Epoch 154/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1003 - accuracy: 0.9796 - val_loss: 2.3690 - val_accuracy: 0.7097\n",
            "Epoch 155/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1761 - accuracy: 0.9388 - val_loss: 2.2031 - val_accuracy: 0.7419\n",
            "Epoch 156/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0880 - accuracy: 0.9796 - val_loss: 0.8398 - val_accuracy: 0.7742\n",
            "Epoch 157/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1363 - accuracy: 0.9388 - val_loss: 1.5631 - val_accuracy: 0.7419\n",
            "Epoch 158/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.3164 - accuracy: 0.8980 - val_loss: 0.6307 - val_accuracy: 0.8065\n",
            "Epoch 159/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1119 - accuracy: 0.9592 - val_loss: 1.1724 - val_accuracy: 0.6774\n",
            "Epoch 160/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.1090 - accuracy: 0.9388 - val_loss: 1.0845 - val_accuracy: 0.5806\n",
            "Epoch 161/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.7419\n",
            "Epoch 162/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.7097\n",
            "Epoch 163/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0721 - accuracy: 0.9592 - val_loss: 1.1186 - val_accuracy: 0.6774\n",
            "Epoch 164/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.1563 - accuracy: 0.9592 - val_loss: 1.3507 - val_accuracy: 0.5484\n",
            "Epoch 165/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0429 - accuracy: 0.9796 - val_loss: 1.1688 - val_accuracy: 0.6129\n",
            "Epoch 166/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1718 - accuracy: 0.9592 - val_loss: 1.3829 - val_accuracy: 0.5484\n",
            "Epoch 167/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0708 - accuracy: 0.9592 - val_loss: 0.9152 - val_accuracy: 0.5806\n",
            "Epoch 168/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0828 - accuracy: 0.9592 - val_loss: 0.8294 - val_accuracy: 0.7097\n",
            "Epoch 169/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.7704 - accuracy: 0.9184 - val_loss: 2.2806 - val_accuracy: 0.3548\n",
            "Epoch 170/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 2.6613 - val_accuracy: 0.3226\n",
            "Epoch 171/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 2.3319 - val_accuracy: 0.4839\n",
            "Epoch 172/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 2.2754 - val_accuracy: 0.5161\n",
            "Epoch 173/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.1822 - val_accuracy: 0.5161\n",
            "Epoch 174/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.1183 - val_accuracy: 0.5806\n",
            "Epoch 175/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 2.3265 - val_accuracy: 0.5161\n",
            "Epoch 176/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.0434 - val_accuracy: 0.5806\n",
            "Epoch 177/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.7664 - val_accuracy: 0.6774\n",
            "Epoch 178/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.0268 - accuracy: 0.9796 - val_loss: 1.2968 - val_accuracy: 0.7097\n",
            "Epoch 179/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1181 - val_accuracy: 0.6774\n",
            "Epoch 180/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.9947 - val_accuracy: 0.7097\n",
            "Epoch 181/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.6774\n",
            "Epoch 182/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.6283 - val_accuracy: 0.6774\n",
            "Epoch 183/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.2737 - val_accuracy: 0.6452\n",
            "Epoch 184/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0399 - accuracy: 0.9796 - val_loss: 0.7506 - val_accuracy: 0.6774\n",
            "Epoch 185/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0545 - accuracy: 0.9796 - val_loss: 0.8460 - val_accuracy: 0.5806\n",
            "Epoch 186/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.8739 - val_accuracy: 0.5806\n",
            "Epoch 187/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1039 - accuracy: 0.9796 - val_loss: 1.1054 - val_accuracy: 0.6129\n",
            "Epoch 188/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.2015 - accuracy: 0.9388 - val_loss: 0.9870 - val_accuracy: 0.7097\n",
            "Epoch 189/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0406 - accuracy: 0.9796 - val_loss: 0.3882 - val_accuracy: 0.8710\n",
            "Epoch 190/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.0390 - accuracy: 0.9796 - val_loss: 0.4538 - val_accuracy: 0.8710\n",
            "Epoch 191/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0292 - accuracy: 0.9796 - val_loss: 0.6908 - val_accuracy: 0.8065\n",
            "Epoch 192/300\n",
            "7/7 [==============================] - 24s 4s/step - loss: 0.0923 - accuracy: 0.9796 - val_loss: 1.0999 - val_accuracy: 0.7419\n",
            "Epoch 193/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1337 - accuracy: 0.9592 - val_loss: 1.3143 - val_accuracy: 0.6452\n",
            "Epoch 194/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0651 - accuracy: 0.9796 - val_loss: 1.2707 - val_accuracy: 0.7097\n",
            "Epoch 195/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 1.2847 - val_accuracy: 0.6774\n",
            "Epoch 196/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 1.1877 - val_accuracy: 0.6129\n",
            "Epoch 197/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0418 - accuracy: 0.9796 - val_loss: 0.8755 - val_accuracy: 0.6774\n",
            "Epoch 198/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.9346 - val_accuracy: 0.6774\n",
            "Epoch 199/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0520 - accuracy: 0.9796 - val_loss: 0.6416 - val_accuracy: 0.7419\n",
            "Epoch 200/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0264 - accuracy: 0.9796 - val_loss: 0.7870 - val_accuracy: 0.8065\n",
            "Epoch 201/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1143 - accuracy: 0.9592 - val_loss: 1.7083 - val_accuracy: 0.7742\n",
            "Epoch 202/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.1740 - accuracy: 0.9184 - val_loss: 1.1865 - val_accuracy: 0.7742\n",
            "Epoch 203/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1220 - accuracy: 0.9388 - val_loss: 0.8562 - val_accuracy: 0.8387\n",
            "Epoch 204/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.2374 - accuracy: 0.9592 - val_loss: 2.2795 - val_accuracy: 0.7097\n",
            "Epoch 205/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0797 - accuracy: 0.9796 - val_loss: 2.7823 - val_accuracy: 0.6774\n",
            "Epoch 206/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0830 - accuracy: 0.9592 - val_loss: 0.7222 - val_accuracy: 0.8065\n",
            "Epoch 207/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0579 - accuracy: 0.9796 - val_loss: 1.3787 - val_accuracy: 0.8387\n",
            "Epoch 208/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0592 - accuracy: 0.9796 - val_loss: 5.1027 - val_accuracy: 0.7742\n",
            "Epoch 209/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0762 - accuracy: 0.9796 - val_loss: 19.7209 - val_accuracy: 0.7419\n",
            "Epoch 210/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 32.1018 - val_accuracy: 0.7419\n",
            "Epoch 211/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1173 - accuracy: 0.9796 - val_loss: 8.0275 - val_accuracy: 0.7419\n",
            "Epoch 212/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0743 - accuracy: 0.9796 - val_loss: 5.5064 - val_accuracy: 0.7419\n",
            "Epoch 213/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0544 - accuracy: 0.9796 - val_loss: 1.3221 - val_accuracy: 0.7419\n",
            "Epoch 214/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1531 - accuracy: 0.9388 - val_loss: 0.7278 - val_accuracy: 0.8065\n",
            "Epoch 215/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.0225 - val_accuracy: 0.8710\n",
            "Epoch 216/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0727 - accuracy: 0.9592 - val_loss: 1.0553 - val_accuracy: 0.8065\n",
            "Epoch 217/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.8006 - val_accuracy: 0.7742\n",
            "Epoch 218/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0777 - accuracy: 0.9592 - val_loss: 0.3938 - val_accuracy: 0.8065\n",
            "Epoch 219/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.9788 - val_accuracy: 0.7742\n",
            "Epoch 220/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.9845 - val_accuracy: 0.7419\n",
            "Epoch 221/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0525 - accuracy: 0.9796 - val_loss: 0.3474 - val_accuracy: 0.8710\n",
            "Epoch 222/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1238 - accuracy: 0.9388 - val_loss: 1.0652 - val_accuracy: 0.8065\n",
            "Epoch 223/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0423 - accuracy: 0.9796 - val_loss: 1.1481 - val_accuracy: 0.7742\n",
            "Epoch 224/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.4230 - val_accuracy: 0.7742\n",
            "Epoch 225/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.2026 - accuracy: 0.9184 - val_loss: 0.7979 - val_accuracy: 0.8387\n",
            "Epoch 226/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1366 - accuracy: 0.9592 - val_loss: 1.3433 - val_accuracy: 0.8065\n",
            "Epoch 227/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.3316 - val_accuracy: 0.7742\n",
            "Epoch 228/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0857 - accuracy: 0.9592 - val_loss: 0.7866 - val_accuracy: 0.6452\n",
            "Epoch 229/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0506 - accuracy: 0.9592 - val_loss: 0.6066 - val_accuracy: 0.7097\n",
            "Epoch 230/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.6452\n",
            "Epoch 231/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.7097\n",
            "Epoch 232/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0468 - val_accuracy: 0.7097\n",
            "Epoch 233/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.2508 - val_accuracy: 0.7097\n",
            "Epoch 234/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3232 - val_accuracy: 0.7097\n",
            "Epoch 235/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.2384 - accuracy: 0.9796 - val_loss: 1.6291 - val_accuracy: 0.6774\n",
            "Epoch 236/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0417 - accuracy: 0.9592 - val_loss: 2.4082 - val_accuracy: 0.4516\n",
            "Epoch 237/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0307 - accuracy: 0.9796 - val_loss: 3.4684 - val_accuracy: 0.2903\n",
            "Epoch 238/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0308 - accuracy: 0.9796 - val_loss: 3.0980 - val_accuracy: 0.3871\n",
            "Epoch 239/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0892 - accuracy: 0.9592 - val_loss: 1.0069 - val_accuracy: 0.7097\n",
            "Epoch 240/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2759 - val_accuracy: 0.6774\n",
            "Epoch 241/300\n",
            "7/7 [==============================] - 30s 4s/step - loss: 0.0955 - accuracy: 0.9796 - val_loss: 1.3357 - val_accuracy: 0.6129\n",
            "Epoch 242/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.1953 - val_accuracy: 0.6452\n",
            "Epoch 243/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0296 - accuracy: 0.9796 - val_loss: 1.1622 - val_accuracy: 0.6774\n",
            "Epoch 244/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0650 - accuracy: 0.9592 - val_loss: 1.2984 - val_accuracy: 0.5806\n",
            "Epoch 245/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.1693 - val_accuracy: 0.6774\n",
            "Epoch 246/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.1252 - val_accuracy: 0.6774\n",
            "Epoch 247/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.0699 - val_accuracy: 0.6774\n",
            "Epoch 248/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9699 - val_accuracy: 0.6774\n",
            "Epoch 249/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.9108 - val_accuracy: 0.7097\n",
            "Epoch 250/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8833 - val_accuracy: 0.7419\n",
            "Epoch 251/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 9.8537e-04 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.7419\n",
            "Epoch 252/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8279 - val_accuracy: 0.7742\n",
            "Epoch 253/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.8065\n",
            "Epoch 254/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.1779 - val_accuracy: 0.7097\n",
            "Epoch 255/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0275 - accuracy: 0.9796 - val_loss: 1.9497 - val_accuracy: 0.6129\n",
            "Epoch 256/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0232 - accuracy: 0.9796 - val_loss: 4.0265 - val_accuracy: 0.4194\n",
            "Epoch 257/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.4846 - val_accuracy: 0.6129\n",
            "Epoch 258/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0937 - val_accuracy: 0.7097\n",
            "Epoch 259/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0277 - val_accuracy: 0.7097\n",
            "Epoch 260/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.2006 - accuracy: 0.9592 - val_loss: 2.3453 - val_accuracy: 0.6452\n",
            "Epoch 261/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1927 - accuracy: 0.9592 - val_loss: 1.1696 - val_accuracy: 0.8065\n",
            "Epoch 262/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0653 - accuracy: 0.9796 - val_loss: 1.6367 - val_accuracy: 0.8065\n",
            "Epoch 263/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.9441 - val_accuracy: 0.8065\n",
            "Epoch 264/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0354 - accuracy: 0.9796 - val_loss: 1.3107 - val_accuracy: 0.8065\n",
            "Epoch 265/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0726 - accuracy: 0.9796 - val_loss: 0.9239 - val_accuracy: 0.8065\n",
            "Epoch 266/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1371 - accuracy: 0.9592 - val_loss: 0.9547 - val_accuracy: 0.8387\n",
            "Epoch 267/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.3369 - accuracy: 0.8980 - val_loss: 0.8426 - val_accuracy: 0.7419\n",
            "Epoch 268/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0498 - accuracy: 0.9796 - val_loss: 2.1736 - val_accuracy: 0.6129\n",
            "Epoch 269/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1269 - accuracy: 0.9592 - val_loss: 2.8364 - val_accuracy: 0.4839\n",
            "Epoch 270/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.1571 - accuracy: 0.9184 - val_loss: 1.7420 - val_accuracy: 0.7097\n",
            "Epoch 271/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.0524 - accuracy: 0.9796 - val_loss: 1.4908 - val_accuracy: 0.7742\n",
            "Epoch 272/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0849 - accuracy: 0.9592 - val_loss: 1.5784 - val_accuracy: 0.7742\n",
            "Epoch 273/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.0383 - accuracy: 0.9796 - val_loss: 0.7441 - val_accuracy: 0.8065\n",
            "Epoch 274/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.1162 - accuracy: 0.9592 - val_loss: 1.2483 - val_accuracy: 0.8065\n",
            "Epoch 275/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.1085 - accuracy: 0.9796 - val_loss: 1.3778 - val_accuracy: 0.7419\n",
            "Epoch 276/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.0379 - val_accuracy: 0.7419\n",
            "Epoch 277/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.1567 - accuracy: 0.9796 - val_loss: 1.6811 - val_accuracy: 0.7097\n",
            "Epoch 278/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.0609 - accuracy: 0.9796 - val_loss: 3.0666 - val_accuracy: 0.4839\n",
            "Epoch 279/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.0799 - accuracy: 0.9796 - val_loss: 1.9857 - val_accuracy: 0.6452\n",
            "Epoch 280/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0922 - accuracy: 0.9796 - val_loss: 1.1901 - val_accuracy: 0.7097\n",
            "Epoch 281/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0597 - accuracy: 0.9592 - val_loss: 1.0237 - val_accuracy: 0.6452\n",
            "Epoch 282/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 1.1543 - val_accuracy: 0.6774\n",
            "Epoch 283/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.0311 - accuracy: 0.9796 - val_loss: 1.2422 - val_accuracy: 0.6452\n",
            "Epoch 284/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0360 - accuracy: 0.9796 - val_loss: 1.2616 - val_accuracy: 0.6452\n",
            "Epoch 285/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0307 - accuracy: 0.9796 - val_loss: 1.1889 - val_accuracy: 0.6452\n",
            "Epoch 286/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0981 - val_accuracy: 0.7097\n",
            "Epoch 287/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0185 - val_accuracy: 0.7097\n",
            "Epoch 288/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.9497 - val_accuracy: 0.7419\n",
            "Epoch 289/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9021 - val_accuracy: 0.7419\n",
            "Epoch 290/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8271 - val_accuracy: 0.7097\n",
            "Epoch 291/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8075 - val_accuracy: 0.7097\n",
            "Epoch 292/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.7097\n",
            "Epoch 293/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.7097\n",
            "Epoch 294/300\n",
            "7/7 [==============================] - 26s 4s/step - loss: 4.9384e-04 - accuracy: 1.0000 - val_loss: 0.7726 - val_accuracy: 0.7097\n",
            "Epoch 295/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7809 - val_accuracy: 0.7097\n",
            "Epoch 296/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 8.0153e-04 - accuracy: 1.0000 - val_loss: 0.8292 - val_accuracy: 0.7097\n",
            "Epoch 297/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8514 - val_accuracy: 0.7097\n",
            "Epoch 298/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 6.2624e-04 - accuracy: 1.0000 - val_loss: 0.8684 - val_accuracy: 0.7419\n",
            "Epoch 299/300\n",
            "7/7 [==============================] - 25s 4s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8656 - val_accuracy: 0.7419\n",
            "Epoch 300/300\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8348 - val_accuracy: 0.7097\n"
          ]
        }
      ],
      "source": [
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "r = model.fit(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=300,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FnnySpFjwaJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "QIkP5kbCjzzO",
        "outputId": "2841a2ab-3cbc-47f8-fd7f-60b0378c952e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy \n",
        "from sklearn import metrics \n",
        " \n",
        "actual = numpy.random.binomial(1,.9,size = 1000) \n",
        "predicted = numpy.random.binomial(1,.9,size = 1000) \n",
        " \n",
        "confusion_matrix = metrics.confusion_matrix(actual, predicted) \n",
        " \n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True]) \n",
        " \n",
        "cm_display.plot() \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "c9InTlv9D1ZJ",
        "outputId": "a30e11de-0ab2-489e-f43e-4568a87b69c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}