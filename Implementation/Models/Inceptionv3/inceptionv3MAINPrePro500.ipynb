{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SI9Y8IdyEty"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyFy4wDzyQPQ"
      },
      "outputs": [],
      "source": [
        "class LogisticEndpoint(keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super(LogisticEndpoint, self).__init__(name=name)\n",
        "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
        "\n",
        "    def call(self, targets, logits, sample_weights=None):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        loss = self.loss_fn(targets, logits, sample_weights)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # Log accuracy as a metric and add it\n",
        "        # to the layer using `self.add_metric()`.\n",
        "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
        "        self.add_metric(acc, name=\"accuracy\")\n",
        "\n",
        "        # Return the inference-time prediction tensor (for `.predict()`).\n",
        "        return tf.nn.softmax(logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrXWCkt_yR_8"
      },
      "outputs": [],
      "source": [
        "layer = LogisticEndpoint()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGAg9UpryTP4"
      },
      "outputs": [],
      "source": [
        "targets = tf.ones((2, 2))\n",
        "logits = tf.ones((2, 2))\n",
        "y = layer(targets, logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5odzsqCyUxd",
        "outputId": "efa03ecf-f2e3-49c2-8c12-25daf152e441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer.metrics: [<keras.metrics.BinaryAccuracy object at 0x7f2948be5ad0>]\n",
            "current accuracy value: 1.0\n"
          ]
        }
      ],
      "source": [
        "print(\"layer.metrics:\", layer.metrics)\n",
        "print(\"current accuracy value:\", float(layer.metrics[0].result()))\n",
        "inputs = keras.Input(shape=(3,), name=\"inputs\")\n",
        "targets = keras.Input(shape=(10,), name=\"targets\")\n",
        "logits = keras.layers.Dense(10)(inputs)\n",
        "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3hQrNjcyWOz"
      },
      "outputs": [],
      "source": [
        "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
        "model.compile(optimizer=\"adam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCJrTrm0yX6Z",
        "outputId": "103ad246-506e-42d4-ae3a-71a9c8c91961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 683ms/step - loss: 0.9840 - binary_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2917b63410>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data = {\n",
        "    \"inputs\": np.random.random((3, 3)),\n",
        "    \"targets\": np.random.random((3, 10)),\n",
        "}\n",
        "model.fit(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfl58HI0yZWZ"
      },
      "outputs": [],
      "source": [
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "#from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "#from keras.models import Model\n",
        "#from keras.layers import Input\n",
        "#from keras.layers import Conv2D\n",
        "#from keras.layers import MaxPooling2D\n",
        "#from keras.layers.merge import concatenate\n",
        "#from keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnHKLt3Qya4E"
      },
      "outputs": [],
      "source": [
        "#inception naive version\n",
        "\n",
        "def inception_module(x, f1, f2, f3):\n",
        "\t# 1x1 conv\n",
        "\tconv1 =  keras.layers.Conv2D(f1, (1,1), padding='same', activation='relu')(x)\n",
        "\t# 3x3 conv\n",
        "\tconv3 = keras.layers.Conv2D(f2, (3,3), padding='same', activation='relu')(x)\n",
        "\t# 5x5 conv\n",
        "\tconv5 = keras.layers.Conv2D(f3, (5,5), padding='same', activation='relu')(x)\n",
        "\t# 3x3 max pooling\n",
        "\tpool = keras.layers.MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n",
        "\t# concatenate filters\n",
        "\tout = keras.layers.merge.concatenate([conv1, conv3, conv5, pool])\n",
        "\treturn out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Smpq7SD0ycXi"
      },
      "outputs": [],
      "source": [
        "img_input = keras.Input(shape=(299, 299, 3))\n",
        "classes=2\n",
        "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "WEIGHTS_PATH = 'inception_v3_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "WEIGHTS_PATH = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "channel_axis=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZY3MWbMyeNI"
      },
      "outputs": [],
      "source": [
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-9H_vSOyfhV",
        "outputId": "c975b024-0296-465d-8360-047afbeec341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 49 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/prepro/clahee/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 10,\n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0nm4O1xzFx_",
        "outputId": "780c3806-d7ab-4575-961b-e8d177dea86f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/prepro/clahee/test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 10,\n",
        "                                            class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flJpny7hzMx7"
      },
      "outputs": [],
      "source": [
        "def conv2d_bn(x,filters,num_row,num_col,padding='same',strides=(1, 1)):\n",
        "   \n",
        "    x = keras.layers.Conv2D(filters, (num_row, num_col),strides=strides,padding=padding)(x)\n",
        "    x = keras.layers.BatchNormalization(axis=3, scale=False)(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UYQK4GEzN5j"
      },
      "outputs": [],
      "source": [
        "def inc_block_a(x):    \n",
        "    branch1x1 = conv2d_bn(x, 64, 1, 1)  # 64 filters of 1*1\n",
        "\n",
        "    branch5x5 = conv2d_bn(x, 48, 1, 1)  #48 filters of 1*1\n",
        "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "    x = keras.layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool], axis=channel_axis)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTxMXdw1zO_m"
      },
      "outputs": [],
      "source": [
        "def reduction_block_a(x):  \n",
        "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_pool = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    x = keras.layers.concatenate([branch3x3, branch3x3dbl, branch_pool],axis=channel_axis)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kbly5BNzQEz"
      },
      "outputs": [],
      "source": [
        "# 17 x 17 x 768\n",
        "def inc_block_b(x):\n",
        "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "    branch_pool = keras.layers.AveragePooling2D((3, 3), strides=(1, 1),padding='same')(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "    x = keras.layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool], axis=channel_axis)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg9z9_VJzRMo"
      },
      "outputs": [],
      "source": [
        "# mixed 8: 8 x 8 x 1280\n",
        "def reduction_block_b(x): \n",
        "    branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
        "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
        "    branch7x7x3 = conv2d_bn( branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_pool = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    x = keras.layers.concatenate([branch3x3, branch7x7x3, branch_pool], axis=channel_axis)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcEZcchHzSgF"
      },
      "outputs": [],
      "source": [
        "def inc_block_c(x):        \n",
        "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
        "\n",
        "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
        "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
        "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
        "        branch3x3 = keras.layers.concatenate([branch3x3_1, branch3x3_2],axis=channel_axis)\n",
        "\n",
        "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
        "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
        "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
        "        branch3x3dbl = keras.layers.concatenate([branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n",
        "\n",
        "        branch_pool = keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "        x = keras.layers.concatenate( [branch1x1, branch3x3, branch3x3dbl, branch_pool],axis=channel_axis)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z9G-GN1zTsi"
      },
      "outputs": [],
      "source": [
        "img_input = keras.Input(shape=(299, 299, 3))  #shape=(None, 299, 299, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlSa-5kEzU6k",
        "outputId": "3135b4b8-a501-450b-ceb9-a55f38c0bd0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 149, 149, 32  896         ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 147, 147, 32  9248        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 147, 147, 64  18496       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5200        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138432      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12352       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9264        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55392       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12352       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76864       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 35, 35, 96)   83040       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6176        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16448       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12336       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55392       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['concatenate[0][0]']            \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16448       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76864       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 35, 35, 96)   83040       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 35, 35, 32)   8224        ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 35, 35, 32)  96          ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 35, 35, 256)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 35, 35, 64)   16448       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 35, 35, 48)   12336       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55392       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 35, 35, 256)  0          ['concatenate_1[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 35, 35, 64)   16448       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76864       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 35, 35, 96)   83040       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 35, 35, 32)   8224        ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 35, 35, 32)  96          ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 35, 35, 256)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 35, 35, 64)   16448       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55392       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 17, 17, 384)  885120      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 17, 17, 96)   83040       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 256)  0          ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 17, 17, 736)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 17, 17, 128)  94336       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 17, 17, 128)  94336       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 17, 17, 736)  0          ['concatenate_3[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 17, 17, 192)  141504      ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 17, 17, 192)  141504      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 17, 17, 128)  98432       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 17, 17, 128)  384        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 17, 17, 128)  384        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 17, 17, 128)  98432       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 17, 17, 128)  384        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 17, 17, 128)  384        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 17, 17, 128)  384        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 17, 17, 128)  384        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['concatenate_4[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147648      ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147648      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 17, 17, 128)  98432       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 17, 17, 128)  384        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 17, 17, 128)  384        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 17, 17, 128)  98432       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 17, 17, 128)  384        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 17, 17, 128)  384        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 17, 17, 128)  384        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 17, 17, 128)  384        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['concatenate_5[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147648      ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147648      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 17, 17, 128)  98432       ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 17, 17, 128)  384        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 17, 17, 128)  384        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 17, 17, 128)  98432       ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 17, 17, 128)  384        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 17, 17, 128)  384        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 17, 17, 128)  114816      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 17, 17, 128)  384        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 17, 17, 128)  384        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['concatenate_6[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147648      ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 17, 17, 192)  172224      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147648      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147648      ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258240      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147648      ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258240      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 8, 8, 320)    553280      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331968      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573888      ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491904      ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548672     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['concatenate_8[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409920      ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245952      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'concatenate_9[0][0]',          \n",
            "                                                                  'concatenate_10[0][0]',         \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917952      ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786816      ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548672     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442752      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['concatenate_11[0][0]']         \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655680      ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393408      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'concatenate_12[0][0]',         \n",
            "                                                                  'concatenate_13[0][0]',         \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['concatenate_14[0][0]']         \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " predictions (Dense)            (None, 2)            4098        ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20,033,378\n",
            "Trainable params: 20,000,610\n",
            "Non-trainable params: 32,768\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# input image size: 299 x 299 x 3\n",
        "x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid') # 149 x 149 x 32\n",
        "x = conv2d_bn(x, 32, 3, 3, padding='valid')  # 147 x 147 x 32\n",
        "x = conv2d_bn(x, 64, 3, 3) # 147 x 147 x 64\n",
        "\n",
        "x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)   # 73  x 73 x 64\n",
        "x = conv2d_bn(x, 80, 1, 1, padding='valid') # 73 x 73 x 80\n",
        "x = conv2d_bn(x, 192, 3, 3, padding='valid')  # 71 x 71 x 192\n",
        "x = keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)  # 35 x 35 x 192\n",
        "\n",
        "\n",
        "x=inc_block_a(x) #35, 35, 256\n",
        "x=inc_block_a(x) #35, 35, 256\n",
        "x=inc_block_a(x) #35, 35, 256\n",
        "\n",
        "x=reduction_block_a(x) #17, 17, 736\n",
        "\n",
        "x=inc_block_b(x) #17, 17, 768\n",
        "x=inc_block_b(x) #17, 17, 768\n",
        "x=inc_block_b(x) #17, 17, 768\n",
        "x=inc_block_b(x) #17, 17, 768\n",
        "\n",
        "x=reduction_block_b(x) #shape=(None, 8, 8, 1280)\n",
        "\n",
        "x=inc_block_c(x) # shape=(None, 8, 8, 2048) \n",
        "x=inc_block_c(x) # shape=(None, 8, 8, 2048) \n",
        "\n",
        "x = keras.layers.GlobalAveragePooling2D(name='avg_pool')(x) # shape=(None, 2048)\n",
        "\n",
        "x = keras.layers.Dense(classes, activation='softmax', name='predictions')(x) #shape=(None, 1000) \n",
        "\n",
        "\n",
        "\n",
        "# Create model.\n",
        "inputs = img_input\n",
        "model =  keras.Model(inputs, x, name='inception_v3')\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXIYWsd2zWQL"
      },
      "outputs": [],
      "source": [
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3WfNt4VzY6-",
        "outputId": "4bf9bc72-72b1-4e21-a774-23dae34be48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 50s 6s/step - loss: 2.2953 - accuracy: 0.4898 - val_loss: 0.6833 - val_accuracy: 0.7419\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 1.4346 - accuracy: 0.6327 - val_loss: 0.8497 - val_accuracy: 0.2581\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 27s 6s/step - loss: 0.8291 - accuracy: 0.6735 - val_loss: 0.8698 - val_accuracy: 0.2581\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.5131 - accuracy: 0.6939 - val_loss: 0.8355 - val_accuracy: 0.2581\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.4655 - accuracy: 0.7959 - val_loss: 0.7959 - val_accuracy: 0.2581\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.5114 - accuracy: 0.7347 - val_loss: 0.9114 - val_accuracy: 0.2581\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.5084 - accuracy: 0.7959 - val_loss: 0.9697 - val_accuracy: 0.2581\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.4991 - accuracy: 0.7755 - val_loss: 0.7486 - val_accuracy: 0.2581\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.4692 - accuracy: 0.8571 - val_loss: 0.6669 - val_accuracy: 0.7419\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 27s 5s/step - loss: 0.4193 - accuracy: 0.8163 - val_loss: 0.7460 - val_accuracy: 0.2581\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.3500 - accuracy: 0.8571 - val_loss: 0.9831 - val_accuracy: 0.2581\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.3445 - accuracy: 0.8571 - val_loss: 0.7735 - val_accuracy: 0.2581\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 27s 6s/step - loss: 0.6376 - accuracy: 0.7755 - val_loss: 0.5709 - val_accuracy: 0.7419\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.4475 - accuracy: 0.8367 - val_loss: 0.5973 - val_accuracy: 0.7419\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.3838 - accuracy: 0.8776 - val_loss: 0.5684 - val_accuracy: 0.7419\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.4282 - accuracy: 0.8367 - val_loss: 0.5817 - val_accuracy: 0.7419\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 27s 6s/step - loss: 0.3470 - accuracy: 0.8367 - val_loss: 0.5720 - val_accuracy: 0.7419\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.3560 - accuracy: 0.8776 - val_loss: 0.6170 - val_accuracy: 0.7419\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.3601 - accuracy: 0.8776 - val_loss: 0.7543 - val_accuracy: 0.7419\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.4581 - accuracy: 0.8367 - val_loss: 0.7249 - val_accuracy: 0.7419\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.2766 - accuracy: 0.9184 - val_loss: 0.6151 - val_accuracy: 0.7419\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1680 - accuracy: 0.9388 - val_loss: 0.6623 - val_accuracy: 0.7419\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.3096 - accuracy: 0.8571 - val_loss: 0.7493 - val_accuracy: 0.7419\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.3541 - accuracy: 0.8571 - val_loss: 0.9787 - val_accuracy: 0.7419\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 27s 6s/step - loss: 0.3412 - accuracy: 0.8367 - val_loss: 1.0884 - val_accuracy: 0.7419\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.4756 - accuracy: 0.7551 - val_loss: 1.2560 - val_accuracy: 0.7419\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2816 - accuracy: 0.8776 - val_loss: 1.1716 - val_accuracy: 0.7419\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 27s 6s/step - loss: 0.2640 - accuracy: 0.8980 - val_loss: 1.3193 - val_accuracy: 0.7419\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1941 - accuracy: 0.8980 - val_loss: 1.5586 - val_accuracy: 0.7419\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2108 - accuracy: 0.9184 - val_loss: 1.7156 - val_accuracy: 0.7419\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0933 - accuracy: 0.9796 - val_loss: 1.8437 - val_accuracy: 0.7419\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2402 - accuracy: 0.8980 - val_loss: 2.0272 - val_accuracy: 0.7419\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1880 - accuracy: 0.9184 - val_loss: 1.9400 - val_accuracy: 0.7419\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2620 - accuracy: 0.8980 - val_loss: 1.6778 - val_accuracy: 0.7419\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2776 - accuracy: 0.8571 - val_loss: 1.2839 - val_accuracy: 0.7419\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 27s 6s/step - loss: 0.2722 - accuracy: 0.8571 - val_loss: 1.4960 - val_accuracy: 0.7419\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0842 - accuracy: 0.9796 - val_loss: 1.8338 - val_accuracy: 0.7419\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1282 - accuracy: 0.9184 - val_loss: 1.7504 - val_accuracy: 0.7419\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2133 - accuracy: 0.9388 - val_loss: 1.3885 - val_accuracy: 0.7419\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1352 - accuracy: 0.9592 - val_loss: 1.8498 - val_accuracy: 0.6129\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1416 - accuracy: 0.9388 - val_loss: 1.4468 - val_accuracy: 0.6129\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1717 - accuracy: 0.9184 - val_loss: 0.9494 - val_accuracy: 0.7419\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.3383 - accuracy: 0.8776 - val_loss: 1.8647 - val_accuracy: 0.5161\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2855 - accuracy: 0.8980 - val_loss: 6.0008 - val_accuracy: 0.3226\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.3722 - accuracy: 0.9184 - val_loss: 0.8368 - val_accuracy: 0.6452\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.1452 - accuracy: 0.9184 - val_loss: 0.7927 - val_accuracy: 0.7419\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.1104 - accuracy: 0.9796 - val_loss: 1.0143 - val_accuracy: 0.7419\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.1607 - accuracy: 0.9184 - val_loss: 0.7997 - val_accuracy: 0.7419\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1348 - accuracy: 0.9592 - val_loss: 1.3435 - val_accuracy: 0.5161\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0577 - accuracy: 0.9796 - val_loss: 1.7166 - val_accuracy: 0.5161\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.3988 - accuracy: 0.8776 - val_loss: 1.2620 - val_accuracy: 0.7419\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1124 - accuracy: 0.9592 - val_loss: 0.8222 - val_accuracy: 0.7419\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1145 - accuracy: 0.9388 - val_loss: 1.3934 - val_accuracy: 0.4839\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.1330 - accuracy: 0.9388 - val_loss: 3.0111 - val_accuracy: 0.3548\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2101 - accuracy: 0.9388 - val_loss: 1.0280 - val_accuracy: 0.5806\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1056 - accuracy: 0.9796 - val_loss: 1.1232 - val_accuracy: 0.6452\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 1.6350 - val_accuracy: 0.4839\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0911 - accuracy: 0.9796 - val_loss: 2.7475 - val_accuracy: 0.5161\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1354 - accuracy: 0.9388 - val_loss: 1.5168 - val_accuracy: 0.4839\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.8750 - val_accuracy: 0.6452\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0475 - accuracy: 0.9796 - val_loss: 1.2528 - val_accuracy: 0.4839\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 1.9006 - val_accuracy: 0.5806\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.1819 - val_accuracy: 0.5806\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0380 - accuracy: 0.9796 - val_loss: 2.2836 - val_accuracy: 0.5806\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1832 - accuracy: 0.9388 - val_loss: 1.8514 - val_accuracy: 0.5484\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.2598 - val_accuracy: 0.5806\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0951 - accuracy: 0.9388 - val_loss: 1.7143 - val_accuracy: 0.5484\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1890 - accuracy: 0.9592 - val_loss: 2.6983 - val_accuracy: 0.4839\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1153 - accuracy: 0.9592 - val_loss: 2.5741 - val_accuracy: 0.4839\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.4883 - accuracy: 0.8776 - val_loss: 3.4177 - val_accuracy: 0.4194\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 4.5200 - val_accuracy: 0.3548\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0951 - accuracy: 0.9796 - val_loss: 5.0784 - val_accuracy: 0.3226\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1563 - accuracy: 0.9184 - val_loss: 3.8800 - val_accuracy: 0.3548\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2586 - accuracy: 0.9184 - val_loss: 1.6952 - val_accuracy: 0.3548\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0918 - accuracy: 0.9796 - val_loss: 1.9017 - val_accuracy: 0.3548\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1272 - accuracy: 0.9388 - val_loss: 2.5712 - val_accuracy: 0.3548\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1023 - accuracy: 0.9592 - val_loss: 2.5276 - val_accuracy: 0.3871\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0668 - accuracy: 0.9796 - val_loss: 2.4338 - val_accuracy: 0.3871\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 2.6679 - val_accuracy: 0.3226\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 2.8119 - val_accuracy: 0.3226\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0501 - accuracy: 0.9796 - val_loss: 2.7743 - val_accuracy: 0.3226\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 1.3435 - val_accuracy: 0.4194\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 1.5856 - val_accuracy: 0.5484\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0834 - accuracy: 0.9796 - val_loss: 2.0364 - val_accuracy: 0.4194\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0858 - accuracy: 0.9388 - val_loss: 1.0407 - val_accuracy: 0.7097\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0873 - accuracy: 0.9796 - val_loss: 1.0824 - val_accuracy: 0.7097\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1341 - accuracy: 0.9388 - val_loss: 1.2824 - val_accuracy: 0.7097\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0694 - accuracy: 0.9592 - val_loss: 1.4669 - val_accuracy: 0.6452\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1069 - accuracy: 0.9592 - val_loss: 1.3298 - val_accuracy: 0.6452\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0818 - accuracy: 0.9592 - val_loss: 1.7391 - val_accuracy: 0.6129\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.3238 - accuracy: 0.8571 - val_loss: 3.8733 - val_accuracy: 0.4516\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1777 - accuracy: 0.8980 - val_loss: 4.5332 - val_accuracy: 0.3871\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2806 - accuracy: 0.9796 - val_loss: 4.6410 - val_accuracy: 0.5161\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2601 - accuracy: 0.9592 - val_loss: 4.1674 - val_accuracy: 0.4839\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1385 - accuracy: 0.9388 - val_loss: 4.9630 - val_accuracy: 0.3548\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.1522 - accuracy: 0.9388 - val_loss: 8.7325 - val_accuracy: 0.3871\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1899 - accuracy: 0.8980 - val_loss: 8.3256 - val_accuracy: 0.4194\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 4.5965 - val_accuracy: 0.4516\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 2.0393 - val_accuracy: 0.5806\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0537 - accuracy: 0.9796 - val_loss: 1.4571 - val_accuracy: 0.7097\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.1376 - val_accuracy: 0.6774\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.9913 - val_accuracy: 0.7742\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1512 - accuracy: 0.9592 - val_loss: 1.2295 - val_accuracy: 0.7419\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0516 - accuracy: 0.9796 - val_loss: 1.7823 - val_accuracy: 0.6452\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2844 - accuracy: 0.8980 - val_loss: 1.1208 - val_accuracy: 0.7097\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0571 - accuracy: 0.9796 - val_loss: 1.4822 - val_accuracy: 0.6129\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1063 - accuracy: 0.9388 - val_loss: 7.0676 - val_accuracy: 0.2903\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0780 - accuracy: 0.9592 - val_loss: 11.1257 - val_accuracy: 0.2903\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 10.4362 - val_accuracy: 0.2903\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0455 - accuracy: 0.9796 - val_loss: 6.8682 - val_accuracy: 0.3871\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 4.9275 - val_accuracy: 0.4194\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 5.6985 - val_accuracy: 0.3548\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 2.1829 - val_accuracy: 0.6774\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.6021 - val_accuracy: 0.7742\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.8100 - val_accuracy: 0.8065\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.3827 - val_accuracy: 0.8065\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.9795 - val_accuracy: 0.8065\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4946 - val_accuracy: 0.7419\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.2795 - val_accuracy: 0.6452\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0728 - accuracy: 0.9592 - val_loss: 0.9695 - val_accuracy: 0.7742\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1637 - val_accuracy: 0.7419\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0389 - accuracy: 0.9796 - val_loss: 1.5192 - val_accuracy: 0.7742\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1117 - accuracy: 0.9592 - val_loss: 1.2837 - val_accuracy: 0.7742\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.2300 - accuracy: 0.9184 - val_loss: 4.1069 - val_accuracy: 0.7742\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1123 - accuracy: 0.9388 - val_loss: 3.1223 - val_accuracy: 0.7097\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2211 - accuracy: 0.9592 - val_loss: 1.0714 - val_accuracy: 0.7419\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 0.9032\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1073 - accuracy: 0.9592 - val_loss: 1.0511 - val_accuracy: 0.8065\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 1.1176 - val_accuracy: 0.8065\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3562 - val_accuracy: 0.8065\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.3385 - val_accuracy: 0.8065\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.1796 - val_accuracy: 0.8065\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9807 - val_accuracy: 0.8387\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0577 - accuracy: 0.9796 - val_loss: 0.7314 - val_accuracy: 0.8387\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.8710\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.8611 - val_accuracy: 0.8065\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.2347 - val_accuracy: 0.8065\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0795 - accuracy: 0.9592 - val_loss: 1.4874 - val_accuracy: 0.8065\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0923 - accuracy: 0.9592 - val_loss: 0.7617 - val_accuracy: 0.8710\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0594 - accuracy: 0.9796 - val_loss: 1.0368 - val_accuracy: 0.6774\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0728 - accuracy: 0.9796 - val_loss: 1.5878 - val_accuracy: 0.6774\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1824 - accuracy: 0.9592 - val_loss: 0.5538 - val_accuracy: 0.7419\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0428 - accuracy: 0.9592 - val_loss: 0.8154 - val_accuracy: 0.7742\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.8216 - val_accuracy: 0.7419\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.8898 - val_accuracy: 0.7742\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.8294 - accuracy: 0.8571 - val_loss: 6.8181 - val_accuracy: 0.2903\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2836 - accuracy: 0.9184 - val_loss: 1.0877 - val_accuracy: 0.6129\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1430 - accuracy: 0.9388 - val_loss: 0.8379 - val_accuracy: 0.7419\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0924 - accuracy: 0.9796 - val_loss: 0.6241 - val_accuracy: 0.7419\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0977 - accuracy: 0.9388 - val_loss: 0.5596 - val_accuracy: 0.8065\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1151 - accuracy: 0.9388 - val_loss: 0.7698 - val_accuracy: 0.7742\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 1.3692 - val_accuracy: 0.8065\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.3804 - val_accuracy: 0.8065\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0795 - accuracy: 0.9592 - val_loss: 0.5266 - val_accuracy: 0.8387\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.1997 - val_accuracy: 0.8065\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0429 - accuracy: 0.9796 - val_loss: 1.2849 - val_accuracy: 0.8065\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0304 - accuracy: 0.9796 - val_loss: 0.9134 - val_accuracy: 0.8387\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8132 - val_accuracy: 0.8710\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.8877 - val_accuracy: 0.8065\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.8065\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.9509 - val_accuracy: 0.8065\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9024 - val_accuracy: 0.8065\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0557 - accuracy: 0.9796 - val_loss: 0.4846 - val_accuracy: 0.8387\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1308 - accuracy: 0.9796 - val_loss: 0.7869 - val_accuracy: 0.8387\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0461 - accuracy: 0.9796 - val_loss: 0.5331 - val_accuracy: 0.8387\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.6635 - val_accuracy: 0.7742\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.9197 - val_accuracy: 0.7419\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0941 - accuracy: 0.9592 - val_loss: 0.7784 - val_accuracy: 0.7419\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0253 - accuracy: 0.9796 - val_loss: 0.9305 - val_accuracy: 0.7742\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0411 - accuracy: 0.9796 - val_loss: 0.8202 - val_accuracy: 0.6774\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.8406 - val_accuracy: 0.7419\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0361 - accuracy: 0.9796 - val_loss: 0.5682 - val_accuracy: 0.7742\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5736 - val_accuracy: 0.8387\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 28s 6s/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.6015 - val_accuracy: 0.8710\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0316 - accuracy: 0.9796 - val_loss: 0.6129 - val_accuracy: 0.8065\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1432 - accuracy: 0.9388 - val_loss: 0.8818 - val_accuracy: 0.8065\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.0729 - val_accuracy: 0.7742\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0788 - accuracy: 0.9388 - val_loss: 0.9489 - val_accuracy: 0.7742\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0841 - val_accuracy: 0.7742\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.1787 - val_accuracy: 0.7742\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1464 - val_accuracy: 0.7097\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1359 - accuracy: 0.9592 - val_loss: 1.3803 - val_accuracy: 0.7742\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0698 - accuracy: 0.9796 - val_loss: 1.2613 - val_accuracy: 0.7742\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2773 - val_accuracy: 0.7742\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0414 - accuracy: 0.9796 - val_loss: 1.3923 - val_accuracy: 0.7742\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.3950 - val_accuracy: 0.7419\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.2032 - val_accuracy: 0.7742\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.1336 - val_accuracy: 0.6774\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.0149 - val_accuracy: 0.7097\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.9351 - val_accuracy: 0.7419\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0707 - accuracy: 0.9592 - val_loss: 0.8953 - val_accuracy: 0.6774\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0294 - accuracy: 0.9796 - val_loss: 1.4111 - val_accuracy: 0.5484\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.4639 - val_accuracy: 0.4516\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0434 - accuracy: 0.9796 - val_loss: 0.6666 - val_accuracy: 0.7419\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.5332 - val_accuracy: 0.7419\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.7742\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0399 - accuracy: 0.9796 - val_loss: 0.5360 - val_accuracy: 0.7419\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.4747 - val_accuracy: 0.6452\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.9213 - val_accuracy: 0.5484\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0920 - accuracy: 0.9388 - val_loss: 1.0003 - val_accuracy: 0.6774\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 2.7269 - val_accuracy: 0.7419\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.4059 - accuracy: 0.9184 - val_loss: 1.8367 - val_accuracy: 0.8065\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1777 - accuracy: 0.9796 - val_loss: 1.8315 - val_accuracy: 0.9032\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0606 - accuracy: 0.9796 - val_loss: 10.3343 - val_accuracy: 0.7419\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2665 - accuracy: 0.8571 - val_loss: 30.2597 - val_accuracy: 0.2581\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0356 - accuracy: 0.9796 - val_loss: 58.3958 - val_accuracy: 0.2581\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0808 - accuracy: 0.9796 - val_loss: 58.8530 - val_accuracy: 0.2581\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1123 - accuracy: 0.9796 - val_loss: 58.5318 - val_accuracy: 0.2581\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 66.3411 - val_accuracy: 0.2581\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 59.9368 - val_accuracy: 0.2581\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0974 - accuracy: 0.9796 - val_loss: 29.0688 - val_accuracy: 0.2581\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0554 - accuracy: 0.9592 - val_loss: 7.7188 - val_accuracy: 0.3871\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0548 - accuracy: 0.9796 - val_loss: 2.6121 - val_accuracy: 0.6774\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0599 - accuracy: 0.9592 - val_loss: 1.5978 - val_accuracy: 0.6774\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1015 - accuracy: 0.9388 - val_loss: 1.2780 - val_accuracy: 0.6774\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0399 - accuracy: 0.9796 - val_loss: 1.7931 - val_accuracy: 0.7419\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0321 - accuracy: 0.9796 - val_loss: 2.4429 - val_accuracy: 0.7419\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.1485 - accuracy: 0.9184 - val_loss: 1.8669 - val_accuracy: 0.7419\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1388 - accuracy: 0.9388 - val_loss: 0.5228 - val_accuracy: 0.8387\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0670 - accuracy: 0.9592 - val_loss: 1.4588 - val_accuracy: 0.8065\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.1724 - accuracy: 0.9592 - val_loss: 1.4138 - val_accuracy: 0.8387\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.1109 - accuracy: 0.9796 - val_loss: 0.4349 - val_accuracy: 0.8387\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.1171 - accuracy: 0.9592 - val_loss: 0.7068 - val_accuracy: 0.8710\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.8926 - val_accuracy: 0.8387\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.7406 - val_accuracy: 0.8387\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0628 - accuracy: 0.9592 - val_loss: 0.6674 - val_accuracy: 0.8065\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.7773 - val_accuracy: 0.8065\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0295 - accuracy: 0.9796 - val_loss: 0.8541 - val_accuracy: 0.8065\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0379 - accuracy: 0.9796 - val_loss: 0.8076 - val_accuracy: 0.8065\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.7830 - val_accuracy: 0.7097\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.1072 - accuracy: 0.9592 - val_loss: 0.8953 - val_accuracy: 0.7742\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8204 - val_accuracy: 0.8065\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.7584 - val_accuracy: 0.8387\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.7462 - val_accuracy: 0.8387\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0326 - accuracy: 0.9796 - val_loss: 0.6701 - val_accuracy: 0.8065\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.2346 - val_accuracy: 0.8387\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.6035 - val_accuracy: 0.8065\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6469 - val_accuracy: 0.8065\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.8065\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.9032\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0201 - accuracy: 0.9796 - val_loss: 1.0511 - val_accuracy: 0.7742\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2918 - val_accuracy: 0.7742\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.3593 - val_accuracy: 0.7742\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.3946 - val_accuracy: 0.7742\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.1345 - val_accuracy: 0.7742\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8775 - val_accuracy: 0.8387\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.7437 - val_accuracy: 0.8387\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8710\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6817 - val_accuracy: 0.8710\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6637 - val_accuracy: 0.8387\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 9.3957e-04 - accuracy: 1.0000 - val_loss: 0.6655 - val_accuracy: 0.8065\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.8065\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 3.4068e-04 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.8065\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.8065\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 6.9712e-04 - accuracy: 1.0000 - val_loss: 0.6798 - val_accuracy: 0.8065\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.8065\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.6683 - val_accuracy: 0.8387\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 3.6058e-04 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 0.8387\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 7.1445e-04 - accuracy: 1.0000 - val_loss: 0.6326 - val_accuracy: 0.8387\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6431 - val_accuracy: 0.8387\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 6.2576e-04 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 0.8065\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 2.6629e-04 - accuracy: 1.0000 - val_loss: 0.6685 - val_accuracy: 0.8065\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 5.1530e-04 - accuracy: 1.0000 - val_loss: 0.6804 - val_accuracy: 0.8065\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.6688 - val_accuracy: 0.8387\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 0.8387\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1832 - accuracy: 0.9592 - val_loss: 1.0768 - val_accuracy: 0.7419\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1088 - accuracy: 0.9796 - val_loss: 4.9220 - val_accuracy: 0.4516\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1009 - accuracy: 0.9592 - val_loss: 1.8827 - val_accuracy: 0.6452\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0525 - accuracy: 0.9796 - val_loss: 1.8114 - val_accuracy: 0.7419\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1792 - accuracy: 0.9388 - val_loss: 1.5810 - val_accuracy: 0.7419\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2102 - accuracy: 0.9184 - val_loss: 2.6573 - val_accuracy: 0.7419\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2587 - accuracy: 0.8776 - val_loss: 1.9606 - val_accuracy: 0.5806\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1160 - accuracy: 0.9592 - val_loss: 1.6308 - val_accuracy: 0.5806\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1201 - accuracy: 0.9796 - val_loss: 0.9831 - val_accuracy: 0.7419\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2583 - accuracy: 0.9388 - val_loss: 3.8548 - val_accuracy: 0.7419\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2424 - accuracy: 0.9184 - val_loss: 8.6774 - val_accuracy: 0.7419\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2372 - accuracy: 0.9184 - val_loss: 17.8406 - val_accuracy: 0.7419\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1100 - accuracy: 0.9592 - val_loss: 19.0978 - val_accuracy: 0.7419\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0668 - accuracy: 0.9796 - val_loss: 10.8635 - val_accuracy: 0.7097\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 3.6065 - val_accuracy: 0.7742\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0591 - accuracy: 0.9796 - val_loss: 1.6081 - val_accuracy: 0.7097\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 1.2008 - val_accuracy: 0.7097\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0759 - accuracy: 0.9592 - val_loss: 1.4272 - val_accuracy: 0.6452\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0524 - accuracy: 0.9796 - val_loss: 1.4410 - val_accuracy: 0.6774\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0372 - accuracy: 0.9796 - val_loss: 1.3215 - val_accuracy: 0.7419\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.8124 - val_accuracy: 0.7419\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.2145 - val_accuracy: 0.7419\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.0386 - val_accuracy: 0.7742\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.6533 - val_accuracy: 0.8387\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.2834 - val_accuracy: 0.8387\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.0450 - val_accuracy: 0.8065\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.9362 - val_accuracy: 0.8387\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 27s 6s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8914 - val_accuracy: 0.9032\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.0466 - val_accuracy: 0.8710\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.0612 - val_accuracy: 0.8387\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0565 - accuracy: 0.9796 - val_loss: 0.9658 - val_accuracy: 0.8710\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8656 - val_accuracy: 0.8387\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0837 - accuracy: 0.9796 - val_loss: 1.3065 - val_accuracy: 0.7419\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1100 - accuracy: 0.9592 - val_loss: 2.1121 - val_accuracy: 0.6774\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.4148 - val_accuracy: 0.6774\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0750 - accuracy: 0.9796 - val_loss: 0.9033 - val_accuracy: 0.8387\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0434 - accuracy: 0.9796 - val_loss: 0.8404 - val_accuracy: 0.8065\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1158 - accuracy: 0.9592 - val_loss: 1.7827 - val_accuracy: 0.8065\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1482 - accuracy: 0.9388 - val_loss: 3.8065 - val_accuracy: 0.8065\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0576 - accuracy: 0.9796 - val_loss: 2.0026 - val_accuracy: 0.8065\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.8713 - val_accuracy: 0.8387\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0454 - accuracy: 0.9796 - val_loss: 1.9139 - val_accuracy: 0.8387\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0548 - accuracy: 0.9796 - val_loss: 2.0956 - val_accuracy: 0.7742\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.9278 - val_accuracy: 0.7419\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0770 - accuracy: 0.9796 - val_loss: 4.7583 - val_accuracy: 0.7419\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0548 - accuracy: 0.9796 - val_loss: 3.1270 - val_accuracy: 0.7419\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0913 - accuracy: 0.9592 - val_loss: 1.4250 - val_accuracy: 0.8387\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1130 - accuracy: 0.9592 - val_loss: 1.2100 - val_accuracy: 0.8710\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1743 - accuracy: 0.9592 - val_loss: 1.5834 - val_accuracy: 0.7742\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.1496 - val_accuracy: 0.7419\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0658 - accuracy: 0.9796 - val_loss: 0.4621 - val_accuracy: 0.8065\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6161 - val_accuracy: 0.8387\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.6438 - val_accuracy: 0.8387\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.8011 - val_accuracy: 0.8065\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3676 - val_accuracy: 0.8065\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6419 - val_accuracy: 0.8065\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.7860 - val_accuracy: 0.8065\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.2304 - val_accuracy: 0.8065\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 9.6912e-04 - accuracy: 1.0000 - val_loss: 0.8629 - val_accuracy: 0.8065\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.6130 - val_accuracy: 0.8387\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 6.6582e-04 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.8387\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.8387\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.9032\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 5.5345e-04 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9032\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9032\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0260 - accuracy: 0.9796 - val_loss: 0.5740 - val_accuracy: 0.8710\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0764 - accuracy: 0.9796 - val_loss: 3.3412 - val_accuracy: 0.7742\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 4.3691 - val_accuracy: 0.7742\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.2310 - accuracy: 0.9592 - val_loss: 1.2429 - val_accuracy: 0.8065\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1473 - accuracy: 0.9388 - val_loss: 2.9465 - val_accuracy: 0.6452\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0859 - accuracy: 0.9796 - val_loss: 3.9017 - val_accuracy: 0.4839\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.2315 - accuracy: 0.9592 - val_loss: 0.8315 - val_accuracy: 0.7419\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0617 - accuracy: 0.9796 - val_loss: 0.5399 - val_accuracy: 0.7419\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1283 - accuracy: 0.9592 - val_loss: 0.4251 - val_accuracy: 0.8065\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1108 - accuracy: 0.9592 - val_loss: 1.3186 - val_accuracy: 0.7742\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 2.0371 - val_accuracy: 0.7419\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0897 - accuracy: 0.9592 - val_loss: 2.1523 - val_accuracy: 0.7419\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.7677 - val_accuracy: 0.8065\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.4350 - val_accuracy: 0.8065\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.5759 - val_accuracy: 0.8065\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.6635 - val_accuracy: 0.7419\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7012 - val_accuracy: 0.7742\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.3423 - val_accuracy: 0.8387\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0458 - accuracy: 0.9796 - val_loss: 0.9610 - val_accuracy: 0.8387\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.8065\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.8387\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0668 - accuracy: 0.9796 - val_loss: 0.5428 - val_accuracy: 0.8065\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.8065\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.8065\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.8387\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.8387\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.8387\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0545 - accuracy: 0.9592 - val_loss: 0.5723 - val_accuracy: 0.8387\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.1500 - val_accuracy: 0.7742\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.3187 - val_accuracy: 0.7419\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.2409 - val_accuracy: 0.7419\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0289 - accuracy: 0.9796 - val_loss: 0.9164 - val_accuracy: 0.7419\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.8065\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0179 - accuracy: 0.9796 - val_loss: 0.6947 - val_accuracy: 0.8065\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.9835 - val_accuracy: 0.8065\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.0984 - val_accuracy: 0.8065\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0779 - val_accuracy: 0.8065\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0504 - val_accuracy: 0.8065\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0321 - val_accuracy: 0.8065\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 8.0494e-04 - accuracy: 1.0000 - val_loss: 0.9977 - val_accuracy: 0.7742\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 2.9628e-04 - accuracy: 1.0000 - val_loss: 0.9714 - val_accuracy: 0.7742\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9262 - val_accuracy: 0.7742\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.8831 - val_accuracy: 0.7742\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3374 - val_accuracy: 0.7419\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0391 - accuracy: 0.9796 - val_loss: 1.7940 - val_accuracy: 0.7097\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 1.3501 - val_accuracy: 0.7419\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.1230 - accuracy: 0.9388 - val_loss: 1.1130 - val_accuracy: 0.6774\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 26s 5s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9407 - val_accuracy: 0.7419\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8768 - val_accuracy: 0.7419\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0273 - accuracy: 0.9796 - val_loss: 0.6883 - val_accuracy: 0.7419\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0923 - accuracy: 0.9796 - val_loss: 0.7666 - val_accuracy: 0.7419\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.7742\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.8065\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0314 - accuracy: 0.9796 - val_loss: 0.7311 - val_accuracy: 0.7742\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1373 - val_accuracy: 0.7097\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.1049 - accuracy: 0.9592 - val_loss: 0.8891 - val_accuracy: 0.7419\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1034 - accuracy: 0.9796 - val_loss: 0.7295 - val_accuracy: 0.8065\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8458 - val_accuracy: 0.8387\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9901 - val_accuracy: 0.8065\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.2107 - val_accuracy: 0.7419\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0191 - accuracy: 0.9796 - val_loss: 1.0372 - val_accuracy: 0.7419\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1704 - accuracy: 0.9592 - val_loss: 0.9989 - val_accuracy: 0.8065\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.6132 - val_accuracy: 0.7419\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.1256 - accuracy: 0.9796 - val_loss: 1.1493 - val_accuracy: 0.8387\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6762 - val_accuracy: 0.8387\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0476 - accuracy: 0.9796 - val_loss: 0.4584 - val_accuracy: 0.8387\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0424 - accuracy: 0.9796 - val_loss: 0.4569 - val_accuracy: 0.8065\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0318 - accuracy: 0.9796 - val_loss: 0.8069 - val_accuracy: 0.8065\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0355 - accuracy: 0.9796 - val_loss: 1.8218 - val_accuracy: 0.7097\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 3.5598 - val_accuracy: 0.5161\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 5.1695 - val_accuracy: 0.3871\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 6.2620 - val_accuracy: 0.3548\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 6.5603 - val_accuracy: 0.3548\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0301 - accuracy: 0.9796 - val_loss: 9.7210 - val_accuracy: 0.2581\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 13.1956 - val_accuracy: 0.2581\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 13.1758 - val_accuracy: 0.2581\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 6.9305e-04 - accuracy: 1.0000 - val_loss: 11.9379 - val_accuracy: 0.2581\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 10.6970 - val_accuracy: 0.2581\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0462 - accuracy: 0.9796 - val_loss: 5.2758 - val_accuracy: 0.2581\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.6355 - val_accuracy: 0.5806\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5999 - val_accuracy: 0.7419\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6625 - val_accuracy: 0.7742\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0542 - accuracy: 0.9592 - val_loss: 0.8476 - val_accuracy: 0.7419\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8281 - val_accuracy: 0.8710\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.8710\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0265 - accuracy: 0.9796 - val_loss: 0.5507 - val_accuracy: 0.8387\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 0.8710\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 6.6106e-04 - accuracy: 1.0000 - val_loss: 0.7680 - val_accuracy: 0.9032\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8556 - val_accuracy: 0.8710\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9577 - val_accuracy: 0.8387\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 8.5287e-04 - accuracy: 1.0000 - val_loss: 1.1659 - val_accuracy: 0.8387\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3776 - val_accuracy: 0.7742\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5366 - val_accuracy: 0.7097\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0398 - accuracy: 0.9796 - val_loss: 2.8125 - val_accuracy: 0.6774\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 4.6666e-04 - accuracy: 1.0000 - val_loss: 3.3876 - val_accuracy: 0.5484\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.1060 - accuracy: 0.9796 - val_loss: 3.3899 - val_accuracy: 0.4839\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 3.9718 - val_accuracy: 0.4516\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0993 - accuracy: 0.9592 - val_loss: 1.2309 - val_accuracy: 0.7097\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 1.7753 - val_accuracy: 0.8065\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.8488 - val_accuracy: 0.7419\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.1922 - accuracy: 0.9796 - val_loss: 3.3260 - val_accuracy: 0.7419\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 3.2569 - val_accuracy: 0.7419\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 3.0709 - val_accuracy: 0.7419\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8915 - val_accuracy: 0.7419\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0850 - accuracy: 0.9592 - val_loss: 2.7270 - val_accuracy: 0.7419\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.4681 - val_accuracy: 0.7419\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0446 - accuracy: 0.9796 - val_loss: 2.1713 - val_accuracy: 0.7419\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.3685 - val_accuracy: 0.7419\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0679 - accuracy: 0.9592 - val_loss: 2.4618 - val_accuracy: 0.7742\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.2319 - val_accuracy: 0.7419\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0486 - accuracy: 0.9796 - val_loss: 2.1924 - val_accuracy: 0.7419\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0405 - accuracy: 0.9796 - val_loss: 1.9483 - val_accuracy: 0.7419\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.4768 - val_accuracy: 0.7742\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.2646 - val_accuracy: 0.7419\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.0912 - accuracy: 0.9592 - val_loss: 1.1160 - val_accuracy: 0.7419\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.1563 - accuracy: 0.9796 - val_loss: 1.2012 - val_accuracy: 0.7097\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 23s 5s/step - loss: 0.0284 - accuracy: 0.9796 - val_loss: 1.3207 - val_accuracy: 0.7419\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0790 - accuracy: 0.9592 - val_loss: 1.0325 - val_accuracy: 0.8065\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.9011 - val_accuracy: 0.7742\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.8316 - val_accuracy: 0.8065\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.7972 - val_accuracy: 0.8065\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.8065\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0505 - accuracy: 0.9796 - val_loss: 1.0058 - val_accuracy: 0.8387\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5982 - val_accuracy: 0.7742\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.9354 - val_accuracy: 0.8065\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.4539 - val_accuracy: 0.8387\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.1786 - val_accuracy: 0.8710\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9761 - val_accuracy: 0.8387\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8549 - val_accuracy: 0.8387\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.7770 - val_accuracy: 0.8065\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.7337 - val_accuracy: 0.8387\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.7205 - val_accuracy: 0.8387\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8387\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.8387\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8710\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6626 - val_accuracy: 0.8710\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 0.8710\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5649 - val_accuracy: 0.8387\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6773 - val_accuracy: 0.8065\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.7742\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.7742\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6926 - val_accuracy: 0.7742\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 3.0705e-04 - accuracy: 1.0000 - val_loss: 0.6883 - val_accuracy: 0.8065\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6514 - val_accuracy: 0.8065\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 6.3754e-04 - accuracy: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.8065\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.8065\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0942 - accuracy: 0.9796 - val_loss: 0.5243 - val_accuracy: 0.8387\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.8710\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.9032\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.1412 - accuracy: 0.9592 - val_loss: 0.5671 - val_accuracy: 0.8387\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.4834 - val_accuracy: 0.7742\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0729 - accuracy: 0.9592 - val_loss: 1.6161 - val_accuracy: 0.7419\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.6237 - val_accuracy: 0.7097\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0704 - accuracy: 0.9796 - val_loss: 2.3245 - val_accuracy: 0.7419\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.8020 - val_accuracy: 0.7419\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0933 - accuracy: 0.9796 - val_loss: 5.2845 - val_accuracy: 0.7419\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0862 - accuracy: 0.9796 - val_loss: 14.7031 - val_accuracy: 0.7419\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.1430 - accuracy: 0.9388 - val_loss: 5.2665 - val_accuracy: 0.7742\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.3459 - accuracy: 0.9388 - val_loss: 5.0743 - val_accuracy: 0.8065\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 8.5129 - val_accuracy: 0.7419\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0597 - accuracy: 0.9796 - val_loss: 8.4969 - val_accuracy: 0.7419\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.1714 - accuracy: 0.9592 - val_loss: 4.3353 - val_accuracy: 0.8065\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.1157 - accuracy: 0.9592 - val_loss: 3.7070 - val_accuracy: 0.7742\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0525 - accuracy: 0.9796 - val_loss: 2.9394 - val_accuracy: 0.7742\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.5582 - val_accuracy: 0.7742\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1348 - accuracy: 0.9388 - val_loss: 1.5837 - val_accuracy: 0.6774\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 25s 5s/step - loss: 0.1174 - accuracy: 0.9388 - val_loss: 1.2514 - val_accuracy: 0.6452\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0855 - accuracy: 0.9592 - val_loss: 1.3043 - val_accuracy: 0.7097\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0456 - accuracy: 0.9796 - val_loss: 1.4718 - val_accuracy: 0.7742\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 24s 5s/step - loss: 0.0785 - accuracy: 0.9592 - val_loss: 1.9725 - val_accuracy: 0.6452\n"
          ]
        }
      ],
      "source": [
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "r = model.fit(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=500,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "WXJ7JGTpi80R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "metadata": {
        "id": "MA2sgAhSi98b",
        "outputId": "34c91138-0a3d-44b8-de38-bbb8091f5a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29eXxV1bn//37OkJyMBEKAyCAgFBGBqIC0KE5VUVtrr3O1Wmv15/d6bb22ttSO3tpb2tra2qv1WrWlzlyHatVKLYI4KyAokyIIEgSSIAkJmc6wfn+svXNOTk7IybwPed6v13nt8Zz9rH32/uxnP+tZa4kxBkVRFCXz8PW3AYqiKErXUAFXFEXJUFTAFUVRMhQVcEVRlAxFBVxRFCVDCfTlwYYOHWrGjh3bl4dUFEXJeFauXFlljClJXt+nAj527FhWrFjRl4dUFEXJeERkW6r1GkJRFEXJUFTAFUVRMhQVcEVRlAylT2PgiqIcvITDYcrLy2lsbOxvUzKWUCjEqFGjCAaDae2vAq4oSo9QXl5OQUEBY8eORUT625yMwxjDnj17KC8vZ9y4cWl9R0MoiqL0CI2NjRQXF6t4dxERobi4uFNvMCrgiqL0GCre3aOz508FXPE2216Dig39bYWieBIVcMXb/PkMuHN2f1uhZADV1dXceeedXfrumWeeSXV1ddr7//SnP+XWW2/t0rF6EhVwRVEOCg4k4JFI5IDffe655ygqKuoNs3oVFXBFUQ4K5s+fz+bNmykrK+PGG29k2bJlHH/88Zx99tkcccQRAJxzzjkcc8wxTJkyhbvvvrvlu2PHjqWqqoqtW7cyefJkrrrqKqZMmcJpp51GQ0PDAY+7evVqZs+ezbRp0/jyl7/M3r17Abj99ts54ogjmDZtGhdddBEAL730EmVlZZSVlXHUUUdRW1vbrTJrGqGiKD3OzX9fx/pP9vXobx5xSCE/+eKUdrcvWLCAtWvXsnr1agCWLVvGqlWrWLt2bUta3n333ceQIUNoaGhg5syZnHvuuRQXF7f6nU2bNvHwww/zpz/9iQsuuIDHH3+cSy+9tN3jXnbZZfzhD3/ghBNO4Mc//jE333wzv/vd71iwYAEfffQR2dnZLeGZW2+9lTvuuIM5c+ZQV1dHKBTq1jlRD1xRlIOWWbNmtcqpvv3225k+fTqzZ89m+/btbNq0qc13xo0bR1lZGQDHHHMMW7dubff3a2pqqK6u5oQTTgDg8ssvZ/ny5QBMmzaNSy65hAceeIBAwPrKc+bM4YYbbuD222+nurq6ZX1XUQ9cUZQe50Cecl+Sl5fXMr9s2TL+9a9/8frrr5Obm8uJJ56YMuc6Ozu7Zd7v93cYQmmPZ599luXLl/P3v/+dn//857z33nvMnz+fs846i+eee445c+awePFiDj/88C79PqgHrniZWKy/LVAyiIKCggPGlGtqahg8eDC5ubls3LiRN954o9vHHDRoEIMHD+bll18G4P777+eEE04gFouxfft2TjrpJH75y19SU1NDXV0dmzdvZurUqXzve99j5syZbNy4sVvHVw9c8S7R5v62QMkgiouLmTNnDkceeSRnnHEGZ511Vqvt8+bN46677mLy5MlMmjSJ2bN7Jj114cKFXHPNNdTX1zN+/Hj+/Oc/E41GufTSS6mpqcEYwze/+U2Kior40Y9+xNKlS/H5fEyZMoUzzjijW8cWY0yPFCIdZsyYYXRAByVtGmtgwRg7/9Oa/rVF6ZANGzYwefLk/jYj40l1HkVkpTFmRvK+GkJRvEs03N8WKIqnUQFXvEukKT7fh2+KipIpqIAr3iWaIOCxA7ekU5SBiAq44l0iCZWY4a6lcinKwYwKuOJdErNQEsMpiqIAKuCKl2kl4DpMl6IkowKueJdEr1s9cKUXyM/P79R6r5GWgItIkYg8JiIbRWSDiHxWRIaIyAsissmZDu5tY5UBRmIlpnrgitKGdD3w3wPPG2MOB6YDG4D5wBJjzERgibOsKD1HYh64CrjSAfPnz+eOO+5oWXYHXairq+OUU07h6KOPZurUqTz11FNp/6YxhhtvvJEjjzySqVOn8uijjwKwc+dO5s6dS1lZGUceeSQvv/wy0WiUr33tay373nbbbT1exmQ6bEovIoOAucDXAIwxzUCziHwJONHZbSGwDPhebxipDFAi6oFnLP+YD7ve69nfHDEVzljQ7uYLL7yQ66+/nmuvvRaARYsWsXjxYkKhEE8++SSFhYVUVVUxe/Zszj777LTGn3ziiSdYvXo1a9asoaqqipkzZzJ37lweeughTj/9dH7wgx8QjUapr69n9erV7Nixg7Vr1wJ0aoSfrpJOXyjjgErgzyIyHVgJfAsYbozZ6eyzCxie6ssicjVwNcCYMWO6bbAygNAsFKUTHHXUUVRUVPDJJ59QWVnJ4MGDGT16NOFwmJtuuonly5fj8/nYsWMHu3fvZsSIER3+5iuvvMLFF1+M3+9n+PDhnHDCCbz99tvMnDmTr3/964TDYc455xzKysoYP348W7Zs4brrruOss87itNNO6/UypyPgAeBo4DpjzJsi8nuSwiXGGCMiKZvKGWPuBu4G2xdKN+1VBhLaEjNzOYCn3Jucf/75PPbYY+zatYsLL7wQgAcffJDKykpWrlxJMBhk7NixKbuR7Qxz585l+fLlPPvss3zta1/jhhtu4LLLLmPNmjUsXryYu+66i0WLFnHffff1RLHaJZ0YeDlQbox501l+DCvou0WkFMCZVvSOicqAZX/iJaUCrnTMhRdeyCOPPMJjjz3G+eefD9huZIcNG0YwGGTp0qVs27Yt7d87/vjjefTRR4lGo1RWVrJ8+XJmzZrFtm3bGD58OFdddRXf+MY3WLVqFVVVVcRiMc4991xuueUWVq1a1VvFbKFDD9wYs0tEtovIJGPM+8ApwHrnczmwwJmmXzOgKB1R/TH866fxZaN9gysdM2XKFGpraxk5ciSlpaUAXHLJJXzxi19k6tSpzJgxo1MDKHz5y1/m9ddfZ/r06YgIv/rVrxgxYgQLFy7k17/+NcFgkPz8fP7617+yY8cOrrjiCmJOP/a/+MUveqWMiaTVnayIlAH3AFnAFuAKrPe+CBgDbAMuMMZ8eqDf0e5klbR54cfw6u/jyxc/ApO613ey0rtod7I9Q2e6k01rQAdjzGqgzZex3rii9DyfboHiiXDSTfDYFRoDV5QUaEtMxZsYA/4sKJ7gLGsIRVGSUQFXvIkxID5wc3VVwDOCvhzh62Cks+dPBVzxJiZmxVt88WXF04RCIfbs2aMi3kWMMezZs4dQKJT2d3RQY8WbmJjjgbs+hoqC1xk1ahTl5eVUVlb2tykZSygUYtSoUWnvrwKueJNkAVcP3PMEg0HGjRvX32YMKDSEongTN4SCGwNXD1xRklEBV7xJGw9cBVxRklEBV7xJi4BrFoqitIcKuOJRNI1QUTpCBVzxJi154JqFoijtoQKueBPNQlGUDlEBV7xJmywUFXBFSUYFXPEmJgaIZqEoygFQAVe8iYZQFKVDVMAVb6ICrigdogKueBPtjVBROkQFXPEmbTqzUhQlGb07FG+iIRRF6RAVcMWbuCGUlmUVcEVJRgVc8SZtBnTQNEJFSUYFXPEmOiKPonRIWgM6iMhWoBaIAhFjzAwRGQI8CowFtgIXGGP29o6ZyoBDeyNUlA7pjAd+kjGmzBgzw1meDywxxkwEljjLitJDaGdWitIR3QmhfAlY6MwvBM7pvjmK4qBZKIrSIekKuAH+KSIrReRqZ91wY8xOZ34XMDzVF0XkahFZISIrdLBTJW1UwBWlQ9Id1Pg4Y8wOERkGvCAiGxM3GmOMiKR8xzXG3A3cDTBjxgx9D1bSwxVw7Y1QUdolLQ/cGLPDmVYATwKzgN0iUgrgTCt6y0hlANLGA+9fcxTFi3Qo4CKSJyIF7jxwGrAWeBq43NntcuCp3jJSGYAYQ+vuZNUDV5Rk0gmhDAeeFJvOFQAeMsY8LyJvA4tE5EpgG3BB75mpDDg0jVBROqRDATfGbAGmp1i/BzilN4xSFNuUXuICrjEURWmDtsRUvElLJSZ2qh64orRBBVzxJokCjqiAK0oKVMAVb9LGA9cQiqIkowKueBMNoShKh6iAK97E7Y0Q7FQFXFHaoAKueJPEAR3UA1eUlKiAK94kOYSiKEob9M5QPIp64IrSESrgijdJjIFrGqGipEQFXPEmrUIoommEipICFXDFm2gaoaJ0iAq44k3aeOAq4IqSjAq44k1MjJbBHMSHdmalKG1RAVe8iYZQFKVDVMAV7+FWWGpnVopyQFTAFe+RLODamZWipEQFXPEerretAq4oB0QFXPEeLQKeUImpIRRFaYMKuOI92njgqIArSgpUwBXvkcoD1zRCRWmDCrjiPVLGwNUDV5Rk0hZwEfGLyDsi8oyzPE5E3hSRD0XkURHJ6j0zlYGFphEqSjp0xgP/FrAhYfmXwG3GmAnAXuDKnjRMGcBoFoqipEVaAi4io4CzgHucZQFOBh5zdlkInNMbBioDEA2hKEpapOuB/w74LuDeRcVAtTEm4iyXAyNTfVFErhaRFSKyorKyslvGKgOENg15NISiKKnoUMBF5AtAhTFmZVcOYIy52xgzwxgzo6SkpCs/oQw0UnngmoWiKG0IpLHPHOBsETkTCAGFwO+BIhEJOF74KGBH75mpDCiSvW2NgStKSjr0wI0x3zfGjDLGjAUuAl40xlwCLAXOc3a7HHiq16xUBhbJHrhmoShKSrqTB/494AYR+RAbE7+3Z0xSBjwaA1eUtEgnhNKCMWYZsMyZ3wLM6nmTlAGPphEqSlpoS0zFe2gaoaKkhQq44j3aCLiGUBQlFSrgivfQNEJFSQsVcMV7aAhFUdJCBVzxHi1ZKE53sppGqCgpUQFXPIiOiako6aACrniPlEOqqYArSjIq4Ir30CwURUkLFXDFe6QScM1CUZQ2qIAr3kOzUBQlLVTAFe+hAq4oaaECrniPFrHWNEJFORAq4Ir30M6sFCUtVMAV7+FqtYZQFOWAqIAr3kPTCBUlLVTAFe+RqiGPphEqShtUwBXvoTFwRUkLFXDFe7QZExMNoShKClTAFe+hfaEoSlqogCveQxvyKEpadCjgIhISkbdEZI2IrBORm53140TkTRH5UEQeFZGs3jdXGRjoqPSKkg7peOBNwMnGmOlAGTBPRGYDvwRuM8ZMAPYCV/aemcqAQj1wRUmLDgXcWOqcxaDzMcDJwGPO+oXAOb1ioTLwSG5Kr2mEipKStGLgIuIXkdVABfACsBmoNsZEnF3KgZG9Y6Iy4Ig5Au7z26l64IqSkrQE3BgTNcaUAaOAWcDh6R5ARK4WkRUisqKysrKLZioDijZphBoDV5RUdCoLxRhTDSwFPgsUiUjA2TQK2NHOd+42xswwxswoKSnplrHKAMFE7bRVDLz/zFEUr5JOFkqJiBQ58znAqcAGrJCf5+x2OfBUbxmpDDBijoC3CqFE+88eRfEogY53oRRYKCJ+rOAvMsY8IyLrgUdE5BbgHeDeXrRTGUi0hFBcAdcQiqKkokMBN8a8CxyVYv0WbDxcUXqW5BCKz68Crigp0JaYivdIlYUS0xCKoiSjAq54jzYNedQDV5RUqIAr3iNlFooKuKIkowKueA+jDXkUJR1UwBXvEdNKTEVJBxVwxXu0hFAS0gi1ElNR2qACrniPNiEU9cAVJRUq4Ir3iKXqTlY9cEVJRgVc8R7akEdR0kIFXPEe7WWh6LiYitIKFXDFeyRnobiVmSrgitIKFXDFe7TpzMq5TDUOriitUAFXvEebGLgr4BoHV5REVMAV75GqMytQAVeUJFTAFe/RXghFG/MoSitUwBXv0RJCcUeldysx1QNXlERUwBXvEYtar7tFwLUSU1FSoQKueA8Ti3vdEI+FaxqhorRCBVzxHiYa97pBY+CK0g4q4Ir3MLG41w2ahaIo7aACrniPWCy1B64xcEVpRYcCLiKjRWSpiKwXkXUi8i1n/RAReUFENjnTwb1vrjIgMNF2YuDqgStKIul44BHg28aYI4DZwLUicgQwH1hijJkILHGWFaX7mFi89SVoDFxR2qFDATfG7DTGrHLma4ENwEjgS8BCZ7eFwDm9ZaQywIi1U4mpHriitKJTMXARGQscBbwJDDfG7HQ27QKGt/Odq0VkhYisqKys7IapyoAhOYSiDXkUJSVpC7iI5AOPA9cbY/YlbjPGGCBlkq4x5m5jzAxjzIySkpJuGasMEDQLRVHSIi0BF5EgVrwfNMY84azeLSKlzvZSoKJ3TFQGHMlZKJnQG+E7D8Dqh/vbCmWAkU4WigD3AhuMMb9N2PQ0cLkzfznwVM+bpwxI2oRQMqAS86lr4W/X9LcVygAjkMY+c4CvAu+JyGpn3U3AAmCRiFwJbAMu6B0TlQGHicX7QQHvx8Ajzf1tgTJA6VDAjTGvANLO5lN61hxFwXraKWPgHvXAP93c3xYoAxRtial4j3Y7s/KoB171QX9boAxQVMAV79FuZ1YeFfCmWjsVvZ2UvkWvOMV7tAmheNwDjzoxcO3uVuljVMAV72FMUhaKUwXj1Rh4NOLMqIArfYsKuOI9TDQpC8XjeeBRzUJR+gcVcMV7JIdQvF6JqQKu9BMq4Ir3MO30B+7VhjzRcHxe4+BKH6ICrniPTOvMKpYg4OqNK32ICrjiPdrtzMqrHniCaEea+s8OZcChAq54jzadWXl8VPrEEErivDIwaN4PS/6rXx7eKuCK92jTkMfJSPFsDDzBA4+qBz7gePm38PJvYOVf+vzQKuCK92gTQvF4DDzR69YQysAj3GCn6oErCgcYUs2rHrhWYir9gwq44j0ybVR6rcTsOrW7tDvebqACrniPjMsDT4yBayVm2mx/G34zCe49tb8t6R5uHY201+t276ECrniPWIaNidkqhKIeeNpUb7PTnau9+3D2OCrgivdo44F7PI0wppWYXaKxJj7virnSKVTAFe/RXhqhZysxm8EXjM8r6ZEo4JXv958d3cV1LPrBwVABV7xHxnVmFYbsfGdeBTxtWgn4xv6zI4NJZ1BjRelbkodUy4RKzKx8aNirIZTO0FgDeSX27SWTPfB+RD3wTGHjc/DzQ+LDdx3MtAmhZIAHnqUeeKdprIHQICiZBBUb+tuaHsCDIRQRuU9EKkRkbcK6ISLygohscqaDe9dMhTfuhPB+2Pxif1vS+7SbheJVDzwMWXl2Xj3w9Gna5wj44XZgaK+OeZousUjH+/Qw6XjgfwHmJa2bDywxxkwEljjLSm8yYpqdbl7av3b0BZk2Kn20OSEGrnngadNYA9mFMGgUhOutoGcy/fDfdyjgxpjlwKdJq78ELHTmFwLn9LBdSjKRRjvdt6N/7egLYhHwZdCo9K1CKOqBp40bQgnm2GX3Gs803DdDLwp4Oww3xux05ncBw9vbUUSuFpEVIrKisrKyi4dTaK6z08YM91LSIdoM/uz4stcb8sQSBFxDKOmTLODh+v61p6u49R79UP/R7UpMY4zhANF7Y8zdxpgZxpgZJSUl3T3cwKV5v51m+mtmOkTD4M+KL3tdwKPNkJUbn1fSo42AZ6gH7nreGeSB7xaRUgBnWtFzJikpcbNPBkIWSrQZ/MH4ciZUYvqzbTqcCnh6RJpsyCRUCEHn4ed2y5ppuMIdyxwBfxq43Jm/HHiqZ8wZ4Cy/FV78eeptAyWEYoyNIyd64JlQiekPQiBbe9ZLF/c6DhVBIGTnMz2EEmm0+ex9eA2kk0b4MPA6MElEykXkSmABcKqIbAI+7ywr3eXFn8HyX8GezW23NTkC3rTPu32C9ARuKlaqEIoXG/IYY73JQLa1WSsx08NthRkaFPfAM7US0/W833kA7pgFz/xnnx26w5aYxpiL29l0Sg/borhsfxOKD2u9zvXAMXY+u6DPzeoTXG8mkCjgHvbAww2AsSLkz9JKzHRpJeCZXomZFDqp3Zl6v15AW2J6CVeoUsW5m+og4FzoB3MYxRXwTKnEdEUnK88+dDQGnh5NqQQ8w2PgLn34IFIB9xROaCQ508QYaK6FwkOc7QdxRaZ7MyRWYvr8VsS96N262UHBXFuRqQKeHq4Hnl14EAh40n/uhjv7ABVwrxANxz3MZIEON9htLQLeCx54s0deX1N64GIF0os3uGtTVq5WYnaGlCEUD/6/6ZDchL5ZBXzgkSjaqQQc4gLeUN2zx/5wCfx3KWx7vWd/tyu4XnaigIMj4B55yCQSdj3wPPvWoJWY6ZGqEtOL/286JHvgKuADkAMKuHNhDx5npz1dSfLRS3b6sQcEPFUIBayX5kUPzX1zyXJCKF4M83iNWAw+WGxTCLPynIe1ZG4WShsB399nh1YBT2TXWnjxlv5J0zuQgLsX9uCxdtprtdweSE9sCaFkt14fzI17u17CfbgGc51KTO3MqkMq1sO2V+Gkm2x4zMshsnSIJoVQwvV9lvKqAp7IX86E5b/un1e5dEIo2QWQOxSW/QK2vtJ3tvUlLR54cgjFqx54ciWmeuAdsus9Ox1/YnxdMOfgCaFAn3nhKuCJuK/D/dEngyvaeSVtKyld4QqG7KgvAE9/s+9s60taPPCkEEpWnjcFPJwYQsnSSsx02PWeTYktnhBfF8zJ3L5QEpvQ5wyx0z6Kg6uAJ+L2tdEdT+D9f8Afjul8KlGzI+CFKUbdibgCnhu3cehnum5jG6QHf6ubpMpCAW94aHWVsP7p1uvch37QzQNXD7xDKtbDsMNbD9oRzO3Tyr8eJdHbzhvadl0vogKeiJvG1x1P7+GLYM+HsOvdNI9pYOVf4JkbALHC3F4IJRCCk39o590RYHoCyRAB7+9Ux0e+Aou+CvUJ3eO7cfmsHswD37UWfjoIdq/r/m95kept8Qp5l1BhZrZviEXt9XDcf8IZv4Jj/z+7vo/KogKeiq56eolP3XRH2f5oOfz9W9BYbQV60GibYpVYkRpO8MDn3gil0w+cC97VSlgvDJjQXgjFC5Vcn26x08Sbs+XhmmM98J4Ioay4104/WNy579VVwl++ANXbu29DbxGLQU05FI1pvT67IDMFvGEvYKCg1Iq3+2asAt6PdFUodq+Pz6c7SOuGv8fnp54HucW2YYCbJwvxLJSg02tbdmH7zekfuQR+Myl9myHeECHigRhzux64B/LA3Vd+tx4C7EM7mGtHEOpOJWZTXVz89261086OsfjW/8LWl+GNP8J6j3YQWrfb/sdFo1uvzy5Iv4Ha2/dYx8cL7K+y09xiO3Xj+uVv98nhVcBT0VWhcMMmeSU2jJIO216FiafB9WvhzFvjMbT6PW3tcftCCQ1q/2Lf+Iy9STqTj+xWHnmhEsnNQgkkpxF6IAvF5/T91pjQkMoVcOheJeYvRsKD59r5yg/stPrjzv2GK/xv3AGLLov/jpeocd4OBiV74GmGUOoq4dlvw8Iv9rxtXaHeEXD3vi08BEbNhA1Pt/+dHkQFPBXdEfDQIPsH1qU5xkXtTvs6WTTaetjuk7yVgLseuCPgB/LAW2xZm77druftKQ88VQilvn+70m3xwBMEvGEv5Ay289n51sbkvOCOcHOGP1pu5908/64KuEuzB0MSbpnaeOBpCHhjDfzeGdw7dyh8shoWXQ5blvW4mWnT4oEPja/7zDzYucY+bHoZFfBUJHt6le/bC6Ujr/bjN6x45w+3XrBLpAmqPmwbY440WQHIHxFfl1LA3Ri464EXdvy6uXP1gbcn2wEe8cAPUImJ6d/Weqk88EQBLxgBmNb/fTq4IgBQuyueaVTTyVh24u9Az3e50BO4Aj4oRQilue7ADWDWPx13rgpKbaO79X+DB86FdU/2jr0dkeyBAxx2kp32wYNFBTwVyR74U9faC+WTd+DXE2BZivErnrjaVlwe+jkr4PurYO0T8PodcMex8D/HwLL/bv0d10vPHxZf5wp44s0YabBdzbpeqeutpKp0dIVv3yedKG8/eOCR5rYe1/Pfj3eGnyzgbtZNuME+cPqjwtUV8Ia98Ox3oHyFnc91cn8LSu20dlfnfjexZa37v5VMtpV9nSlnw6etlxs9KOA1222udHZ+6/WhQjs9kBe+8VkoOhTKLoFPN8OHL8Cx11in6bGvw5pH7bVR/2n7v9HT7Nls7033vgUoLYPCkfDmXb3+xpgRAn7H0g9Z8I80szq6SuKNkuyBu57png9hf6VtCQmw/W345w/tBfPuo3bdpDMdQTbw2BWw+Kb4Db1jVevfdT21ggQPPGUMvCEeZwXnYjfxV+QPFsPG52yanevBdkZEIv0QA3/ofPjFqNbr3rgzPp8cQslzBsT+9CO4Zbg9r32NW6m4cw28/Se49zTr5bbywIkLcjRiK6nbO6/hRidkkvBfVTqV32Nm2/8yXW8+mlTxDXEPfP+ett55f1G9vW34BOIDlBxIwCvWw8hj7Pl2nazPnA6XPg5jj4Mnr4ZbhsHvpsHqh3s/3BZuhDUPw+Fnte3+eM71sGOFfXvvRTJCwDdX1PF/K7ZjuvuH7N8Dj38DHv4K7NtpvZ09m228uCYh3pjsgbstrTb9M76uYiPc+3l47Q/w9HV23Xn3wbDJ1gN3Of2/4crFMOXfbFjj3tNh66t2m3vjJnrgwVybTujeuM319qJ2M1AgLmbbXrPThy6ARy5unR1R1wkBb6nE7MMsD/f10q30W/No6+3JHnjpdDt9/X8AA2/+se+9cLdxlvu6bqL2PLcIuNNbpCvgK+6FRy+1r/jJ124sBj8fbt84Ej3wl35tp4d+zk5ThVGa97eNs6fythurbavH33wG7jml5x7QkebW11pnqP64bfgE7FsltB8aDDfY75ZMir/xAIyYbt/OLn7EZoBkD7L/y9+ugZdvbd+OtU/Apn91rQwuW1+25+Hoy9puG3+ine5YCTvfhYVn2zBqD9PhkGpeYOa4ITzxzg62VO3nsJL8jr+Qih2r7M20b4dd3rfDes4twp3QmCXcYG+4RZfBkHHxGPGmF+L7vPRLyCqw2zc+Y9cdcrSdJgr47H+3DWWKD4N1T1jP+pXb4JCj4qlGiTFwERg5wx7rtFusl2qirfNmJ5xqpw9fBHO/G1+fmFp1IA+8YiMUDIdV91v7Wiox+8gDTxpK760AABS/SURBVOzwqXanPd9PXh1f5wu0FfAh4+3Nue6J+LotS+HQOa0fbqlY/7R9Qzr1v9oOVdcZUrUUjDbHBTxvqH2d3rcDanY4Dxtg2yu2he7hZ8a/t9vpD2TVwvgDechhtpHLyT+CEU5l3dv32GOMPc4uf7AYHr4YZl0NZySE8lKFDRqqbbljEVvBecdMa2vxRDj3nq434HriKhtSvGmnbcB0ILa+aj3nWVfZt43qj2HiqW33cz3w9irnqzYBxgp44ptGnhO6yMqDq5c5ocYse+++fBvMvApyilr/VuUH9u0Y4IeVrYfvS5dP3oHHr7QO19jj224vnmAfSjtW2Pt8+5utHzw9RGYI+Fhb8Nc27+m8gO9aa19z3rnfCsDVL9lsEddrbiGp4cwHi9umAiV6qOuegKnn25CJezG4vQWWTofjvwPHXB6/SYoOjX+3YgPcfSJUvW+FPDGEAjDtfNu454Ufxyu0shLGwMwrhs99E1673Q6C7PK3a+y0eKIV8Nrd9mYzMTj7diuCKxfC3xP6USk5PMEDd4T8jT/aTr3KLrHe3vE3wKCkcMeBME5F3oo/w7uPWI9r+5tw+BfgtJ+1DgvUlNvYpsspP4ZpF7UVFxEYd7x9WBZPhD2b4IF/s4J04+bWzbITqdlh/59YxN5UxRNs+cL1cMVz8T7WOyIasd857gYba95fBXu3WSF2Bdznh+FT7AP6ldvsuvMX2sq2f/0UDjs5/rBJfNi+uwiGTYH/96oV60B2vFHYu4/azw9223WPX2WviRX3wud/Eq/YTo5/55VYD7x8BYw7we73wfP2fO9cY9scTDqjbRlf/o31+k/5CeSX2LcOf1Zc5PbttOIN9i3o+G/Hvx+L2Uq9/GH2/Gx71Qop2LJHm62z4D6cEnGvr+ptcOhnW29rqIbnbrSjMh1yFHz0sl0/5nOt90scJ/bE+fD+s/b4xRNsdtgpP7bXkdtQCmzu/OeStaADYlH7VhVpgs9em9qB8Plg3FxYcZ9dLrt04Ar4YUNzubhoAw1vroDgWOt5zbjSXmifvAOn/Tx+gcViNuQRyLYViP+62TauKDoUvvqk9cCGHwlbXrKCcOhx8NEym1sKtjLi9f+Je0/JnPITWHKznT/yPPsnjZoFc78TF51AFpzyo9bfm3QGHPv/7CvXu49YL/PQ4+D0W9qK1bSL4LUkG5Jf0077mT32g+e1Xj/kMJjweXtz/Xayvdn92XDP5+GC++GfSXatewIqbJNtU1OO1FXC63faN4XXbrf7VKy3r/R7t9pXw8ln2xv0rbvt9kM/Z3PZs3Lhld/Biz9r3QjFGHsDr3vSPhQTt+3bYcXdZcQ0GDQy+axb5i2wnuZpP7MhAbDnc/WDkDfM3vhbllnBqSm3Xuuah+0DrOhQePV39juHHGWF4tGv2mvCrUA7ELVO5WJeiRVOgBd+YgU80TM/+Ye2Qu3If7N5+5PPtt7hg+fBfU7MvLHa2lg40j5oaz6Go52HvZv/npUHJ/0Alv7cLm98xv4nTTUw75fw/Pfg7Xvhc/9ht7se+OFfsA+WWBj2bLH/3Sk/gRlft/fK2OPgztm27mbUzNbZE2seile01+2G8SdZJyIWsQ+6ojFWvMRn76ElP7PHnXO9FfsXfmSv2XkL7JtDYluIt+6Oh8EOKWt7fosnWG926yuQlW/3GTQKtr9lu5mo3Ajn/dk6SbGoPX+n39L+/1U6zerCP38Q7+++scbeh+8usucJbPmiYSj7SltHqj0qNtj/4pw/2u+1x6n/Zc9/6fQD29oNpDtxZRGZB/we8AP3GGNSpGfEmTFjhlmxYkXnDmIM/O3f7cXVDp+EDqNg0onkSJjAtuWY6u1QPAGpep/oxDPYeewPGDXu8LYVY4m89j82/rbxufjr7fHfxnz8OrLtNbjoYSs2M74OT14Dez+CK19oJb419WH2NYYZPeQAr5V7t9oKlinn2Hh5e1R/bMM0M660F9joWW2F3hibuTFurvXSZlxhBXbrq7ZrXIArnrei85ez4nHxIePjzcIdXoyWMTdrIwETaS2wQw6zNf7itzdWU1JFmUtpGQydCO/9n70RJ59tL+4xs+Oi9OlHtmb+3UW24ued+63tHy2H6V+BUCHm8zcjHYVEwPYVki6HnWx//4lv2PqF72219RmLLrdiNGik7Ywq2mTfRqLN9pzll1ivNNJgM4Zqd8F1K+z5A/u6//x8K5AFCWGzaAT8Sb7R6odh6X/bc1EyyYZULrzf2rHyL7b+5Mhz29oejcCCMbbPFTdkd83L8MB5Vuzm/cI2317zELzzAHxrjRW5+78Mm1+0v3HFP+IxdYDNS+GhC60tp/6XPW52Adw3zwrTjK/D4u/bfcefCKOPtZWPe7fat9fJZ8NZv4Fnrrf/JQYKR8G+8vgxcofChFPs+a2rsA/pghF2/ntbU78x3XMqlL9l54N5Vvg+fs3+1pf/FyZ+Pr3/O5FPVtsH9Ku/t2+f7pv2Fc9bkX/8Kuupgw155A+zzkDuEEeoq2zWTN5Qa//4E+1999x34LpV3QvJdQIRWWmMmdFmfVcFXET8wAfAqUA58DZwsTFmfXvf6ZKAA7z1Jxprq7jszTHEanexzQznG4HnaCCbWpPDNYFnyKGJekJUSAnrIiOZGqpgZdZMbq07jX1h4ayppZSNLqK+OUpzJMbOmkbys/18bsJQ9jWEyc8O8NBbH1OzZxenlTYy+4jxbIkUc+eSjdxwwiEEC4dTEApyeGkBn+5vZmJJHuLzsaWyjrqmCHWNEb5yj/Uk779yFiu37eWoMYMZV5xHaVGIoN/WF9c1RahvilBV10xBKMBdL22mfG8DxflZzBo7hJwsPyd8poTCUJCGcJSV2/by4sYKzj16FKOH5DAoJ4ikiF3GYgYDLN9UyYe7qrlq6UwiQybiv+5tu//6p21HTMD+b24kVvkBzWueIHf32/y55Lv8anWArw/bxE3Ru2gaVkbO1C/ie/pa+M91VtCzC8EfxPxqPBJtxhSUEjn+uzB6FsEP/mFb/wVyqB8xg+g5d5GXYx9iW6rqOLQ4r6X8rq0Avmevt+IF8LVn+SBnOl+9903mTRlBXnaArxw7hiy/j8F5WTSEo+RlBdizv4lBOUHCd84lGN5Hdq2twzAn/QCp2w1HnEMs3Eh9qIT8qves4Ey7CEYeDav+aqcjptpjlq+0N2/1divS/mz7OuwL2myj/ZVO+CCECYbYMmQuTVMuwueDl96vZH9ThDHFeazZXk1JQTYXzRzNsMIQ0ZghHI0RCrYT1gFi4WY+qYswND+bWF0FG2qyGTk4lxGD7MOrMRylrinC+k/2cfSan5C/7kFb9zFvAQydYIXwr1+yHp6DGTKe985+nnc+aWB47XrmvX6x/b+/U04wlEdWICFnoWIj5tkbkG1OhbrbUGreAhtf/9u/27fEMxa0Dk0YAyJEY4Y9+5sYtmcl0Tf/F9+WpUioiLrzHyG65SUGzbiISHYRb330KZOCuxny8BlIY419Q5l7Y+qTsuI++6CbfpF9wFVutLbMvLIljTQaMzSEo0SiMYyBd7bv5aRJw4jEDAFf/L5w75HaxjAfVtQxubSQ7HANsvUV+6Y44fPx8uxeZ9/qa3bYN4+6CuvgDBlnQ2INe6F2F6b6Y6R6GwDhovH4rlsJIjRFomyp3M+Cf2zk0tmHkpvlZ9zQPLKDPnbVNDIoJ0hRThYFoQA+X9t7Nx16Q8A/C/zUGHO6s/x9ez7ML9r7TpcF3GFfY5iNO2spCAWoaQizubKOjTtrOWpMETtrGqmqa6K+KUpFbSOvbt7DiMIQR40p4v1dteza10h1fbzybFhBNnvrmwlH4+XPCvjIDviobey4JV1ulp+sgK/Vb7aH3yeEAj6ixtAYTp05kZvlp7453ojBvRgjsdb/T3bAR1FuEEEQAZ/Y6a6aRvw+oSlif384n9JANiY0iMJQkFg0zA8bf8uS4FyebChLSIowBHy+lMeJRZspyM1FnHMT8AvRuj1UNmdRkJNFXTMg1naAnKCfnTU2nl4YCpAV8FNV10RO0E8o6CM3y3ql+xrChGMxcoJ+DvdtpzEqbJVR7G3nXIaCvlbnzSeAiSEYJss2dpshRHJLyAr48IvQGImxt76ZUYNziMXsTR8MCLGY/a2uEIkZtu1JnaWTFfDR7Jz3oF8wxu4fCvoYlBMk4PPZrlJE8PkEAfY1Rqisbd0wTAQG52axvynS8j8C5NLImKxamgvHYoCY8+f5TZRxppzBppr6qI9XGw+lJhz3/EfLboZQyxozgeyAj8G5Wfh9gjGG/c1RgmI4KrKao7O3M8JUsSpyKH+XkynMycInVgQFQGwVv4gQicZojsSobYpQ2xhhWEE2n+5vZkQowqCcAJuqheZojEMGhdjfHKWmwf6nh8geDgtUsEqmEPD7CfiEgF8I+HwE/UJ9cxS/Twj6fezd30xJQXar47pU14epqmt93kYW5VBZ20TAL/hFaIrG8Alk+e110xy157KkIJvsQNv/372HxJlvr3flxqYIs/YvYXZgE3c1z2OrKcUnEEtTQhdfP5dJIwo63jEFvSHg5wHzjDHfcJa/ChxrjPmPpP2uBq4GGDNmzDHbtm3r0vE6S3V9M7lZgRavIxoz7NjbwKaKWmaOG0JhKMj7u2r5qGo/pY7XM2FYPrlZflZ9XE19c4SKfU2MGBRif1OEwpwgu/c1UlnbRMwYyvc2EI0Z/D6hoTnKrHFDGDk4h3fLaxian83RY4pY98k+GpqjbN9bT21jhKyAj4LsAEV5WYQCPpoiMUoHhTjm0MHkZQdY98k+9tQ1saa8hkg0Rk1DmKLcIGOL82gMR2mKxNi9r5F9DREMBmPsxWOMIccR0WPHF3PIoBDb9tSza18ju/c1UtdkH0glBdnsa4hQkp9FYU6QaMywrzFMdX2YL5WNJD87wLpPaojEDO/vqiUr4KO+OYIx0ByJEY0Z8rIDjB2ax+bKOkIBe8ywc4PUN0fJz/bj9/mobQzTHI0xbmiec87sfsZAdtBHKOCnIRwlGosR8PuIRg0FoQDTRxdhgJqGMDX1NsWworaJkvxsYsYKcGVtE1NHDaIxHKUwFGRnTSObKuqIxQxRY89LwCc0RqIEfD78PghHDQI0RbueejiqKIfJpYVU1TVx5tRSGsJRPv60nuMmDGVr1X6Wvl/RIsqDcoK2DA1hojErulHHPrD2TRtVRFVdE1l+H5NGFPBhRR07axoI+HzkZQcoKchmtHNN7dnfRG1jpJXYWDG3/38o6KcwFKQwJ8Ds8cXsqWumrilMVsDHB7vraGiOUt8ccfa3D51oLEbQ76O+OYox9r8F+5ZojP19Y+ybHQaM87DPCtiPAA3hKEU5WXy6v4lIzDA0P5uSgmw27a4l4PfRGI4SClpnpyAUIBI1RKIxwjFDNGoIx2JEooag34fBEI4a8rP91DZGWo6biM8n5GcHGJIXpLYxQk1DGGOs8+COzuYTIRT0E43Z8zI0P4vKuiaqapsxyT9oaHkomoT59vzkvKxAy3VVEArgE/sgmlCSz6jBOSz7oJIjSgupaQiza18jU0cOYn+TtfOCmaMpDB0gjHsA+k3AE+muB64oijIQaU/Au9OQZweQmJE/ylmnKIqi9AHdEfC3gYkiMk5EsoCLgL7pQ1FRFEXpeh64MSYiIv8BLMamEd5njDlIx4BSFEXxHt1qyGOMeQ54rodsURRFUTpBRnRmpSiKorRFBVxRFCVDUQFXFEXJUFTAFUVRMpRudWbV6YOJVAJdbYo5FPDIsCJ9hpZ5YKBlHhh0p8yHGmNKklf2qYB3BxFZkaol0sGMlnlgoGUeGPRGmTWEoiiKkqGogCuKomQomSTgd/e3Af2AlnlgoGUeGPR4mTMmBq4oiqK0JpM8cEVRFCUBFXBFUZQMJSMEXETmicj7IvKhiMzvb3t6ChG5T0QqRGRtwrohIvKCiGxypoOd9SIitzvn4F0RObr/LO8aIjJaRJaKyHoRWSci33LWH8xlDonIWyKyxinzzc76cSLyplO2R50umRGRbGf5Q2f72P60vzuIiF9E3hGRZ5zlg7rMIrJVRN4TkdUissJZ16vXtucF3Bk8+Q7gDOAI4GIROaJ/reox/gLMS1o3H1hijJkILHGWwZZ/ovO5GvhjH9nYk0SAbxtjjgBmA9c6/+XBXOYm4GRjzHSgDJgnIrOBXwK3GWMmAHuBK539rwT2Outvc/bLVL4FbEhYHghlPskYU5aQ792717YxxtMf4LPA4oTl7wPf72+7erB8Y4G1CcvvA6XOfCnwvjP/v8DFqfbL1A/wFHDqQCkzkAusAo7FtsgLOOtbrnFs//qfdeYDzn7S37Z3oayjHME6GXgGO4znwV7mrcDQpHW9em173gMHRgLbE5bLnXUHK8ONMTud+V3AcGf+oDoPzmvyUcCbHORldkIJq4EK4AVgM1BtjIk4uySWq6XMzvYaoLhvLe4Rfgd8F3BHkS7m4C+zAf4pIiudwdyhl6/tbg3ooPQuxhgjIgddnqeI5AOPA9cbY/aJxMcAPxjLbIyJAmUiUgQ8CRzezyb1KiLyBaDCGLNSRE7sb3v6kOOMMTtEZBjwgohsTNzYG9d2JnjgA23w5N0iUgrgTCuc9QfFeRCRIFa8HzTGPOGsPqjL7GKMqQaWYsMHRSLiOlCJ5Wops7N9ELCnj03tLnOAs0VkK/AINozyew7uMmOM2eFMK7AP6ln08rWdCQI+0AZPfhq43Jm/HBsndtdf5tRezwZqEl7NMgKxrva9wAZjzG8TNh3MZS5xPG9EJAcb89+AFfLznN2Sy+yei/OAF40TJM0UjDHfN8aMMsaMxd6vLxpjLuEgLrOI5IlIgTsPnAaspbev7f4O/KdZOXAm8AE2dviD/ranB8v1MLATCGNjYFdiY39LgE3Av4Ahzr6CzcbZDLwHzOhv+7tQ3uOwccJ3gdXO58yDvMzTgHecMq8FfuysHw+8BXwI/B+Q7awPOcsfOtvH93cZuln+E4FnDvYyO2Vb43zWuTrV29e2NqVXFEXJUDIhhKIoiqKkQAVcURQlQ1EBVxRFyVBUwBVFUTIUFXBFUZQMRQVcURQlQ1EBVxRFyVD+f3nrwbDbzmgnAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn import metrics\n",
        "\n",
        "actual = numpy.random.binomial(1,.9,size = 1000)\n",
        "predicted = numpy.random.binomial(1,.9,size = 1000)\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h2UnPg5vebAL",
        "outputId": "2084c548-571b-423e-ea25-8623e12b323e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAEHCAYAAAAnLWSJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfeUlEQVR4nO3deZwW1Z3v8c8XkEWRfQkXUEkkGie5EiRujEaEuMUZyL1uiVGiZjDGmMWZJDrj62bPy9yJIfFmokMkIyauuASdGDfUEI0bKnFBjaggEBZZXJC1u3/3jzodHtrufqrh6a5+ur9vX/V6qk6dqjoPD/w8p07VOYoIzMyseV2KLoCZWTVwsDQzy8HB0swsBwdLM7McHCzNzHJwsDQzy6Fb0QVoDd3VI3qyR9HFsBZQ9+5FF8Fa6O2tq9ZExOBdOcexE/aItetqc+V98pktd0fEcU3tl/Q14PNAAM8CZwHDgBuAgcCTwBkRsVVSD+Aa4CBgLXBqRCxu7vodMlj2ZA8O0cSii2Et0G3E3kUXwVrorlcvW7Kr51i7rpbH794rV96uw14e1NQ+ScOBLwMHRMQmSTcBpwEnANMj4gZJVwLnAFekz/URsa+k04AfAac2d303w82sMAHU5fwvh25AL0ndgN2BFcDRwM1p/yxgSlqfnLZJ+ydKUrmTm5kVIgi2Rb5mODBI0vyS7RkRMQMgIpZL+jHwOrAJuIes2f1mRNSk/MuA4Wl9OLA0HVsj6S2ypvqapi7uYGlmhcpZawRYExHjGtshqT9ZbXEU8CYwG2jy/ubOcLA0s8IEQW1lxqeYBLwWEW8ASLoVGA/0k9Qt1S5HAMtT/uXASGBZarb3JevoaZLvWZpZoeqIXEsZrwOHSto93XucCCwEHgBOSnmmAnPS+u1pm7T//igzqpBrlmZWmABqywfC8ueJeEzSzcBTQA3wNDAD+B1wg6Tvp7SZ6ZCZwK8lLQLWkfWcN8vB0swKlaPWmEtEfAv4VoPkV4GDG8m7GTi5Jed3sDSzwgSwrUrG1HWwNLPCBFGRZnhbcLA0s+IE1FZHrHSwNLPiZG/wVAcHSzMrkKil2bcM2w0HSzMrTNbB42BpZtas7DlLB0szs7LqXLM0M2uea5ZmZjkEorZKhqhwsDSzQrkZbmZWRiC2Rteii5GLg6WZFSZ7KN3NcDOzstzBY2ZWRoSoDdcszczKqnPN0syseVkHT3WEoeoopZl1SNXUwVMdpTSzDqs2lGtpjqT9JC0oWd6W9FVJAyTdK+nl9Nk/5ZekyyUtkvSMpLHlyulgaWaFqX+DJ8/S7HkiXoqIMRExBjgI2AjcBlwEzI2I0cDctA1wPDA6LdOAK8qV1cHSzApVF11yLS0wEXglIpYAk4FZKX0WMCWtTwauicyjZPOLD2vupL5naWaFyQbSyB0IB0maX7I9IyJmNJLvNOD6tD40Ilak9ZXA0LQ+HFhacsyylLaCJjhYmllhArEt/+uOayJiXHMZJHUH/hG4+D3XighJOz3jj4OlmRUmgko/lH488FRErErbqyQNi4gVqZm9OqUvB0aWHDcipTXJ9yzNrECiLueS06fZ3gQHuB2YmtanAnNK0s9MveKHAm+VNNcb5ZqlmRUmqFzNUtIewCeAc0uSLwVuknQOsAQ4JaXfCZwALCLrOT+r3PkdLM2sUJUa/Dci3gUGNkhbS9Y73jBvAOe35PwOlmZWmEAe/NfMrJxsKtzqCEPVUUoz66Dk8SzNzMoJaOnbOYVxsDSzQrlmaWZWRoRcszQzKyfr4PHsjmZmZXgOHjOzsrIOHt+zNDMrq1Jv8LQ2B0szK4zf4DEzy6laJixzsDSzwkTAtjoHSzOzZmXNcAdLM7Oy/AaP7bILf/I6h0x6hzfXdOPco/cDYM9+NfzrlUsYOmIrq5Z15wfn7s2Gt/wzthdTTn2FY/7hdSJgySt9mP7DMXz/p4+w++41APTtv4W/LOzP9y8+uOCStg/V9OhQq9V/JdU2mPR8n2bybmitclSze24cwL+dPmqHtFO+tJqnH+rN2X//IZ5+qDenfml1E0dbWxs4aBP/cNJrfPXsIzn/jAl06RJ8fNJyvvnFv+eCzx3FBZ87ihefG8Cf/tDsjKudjFpjKtxW0Zol2FQ/6XlaFrfitTqk5x7rzTvrd6w1Hnbs29x30wAA7rtpAIcd93YRRbMmdO1aR/cetXTpWkePnrWsXdPzb/t67b6NA8eu4ZF57yuwhO1PhefgaTVtFq4l9ZY0V9JTkp6VNLmRPMMkzUs10eckHZHSj5H0SDp2tqTebVXu9qb/oG2sW70bAOtWd6P/oG0Fl8jqrV3Ti1uv35erb72X38y5h3ff7cbTjw/52/7DjlzJgicHsWnjbgWWsn3JesO75lrKkdRP0s2SXpT0gqTDJA2QdK+kl9Nn/5RXki6XtEjSM5LGljt/awbLXiVN8NuAzcCnImIsMAG4TFLD/118Brg7IsYABwILJA0CLgEmpWPnAxc2vJikaZLmS5q/jS2t+LXaExFVcr+nM+i951YOPWIlZ588iTMmH0PPnrVMOGbp3/Z/fNJy/nDf8AJL2P7UP5SeZ8nhZ8BdEbE/Wfx4AbgImBsRo4G5aRuyKXNHp2UacEW5k7dVM/xTgIAfSnoGuA8YDgxtcMwTwFmSvg18JCLeAQ4FDgAelrSAbDrLvRteLCJmRMS4iBi3Gz1a71sVbP2a3RgwJKtNDhiyjTfXunOnvRgzbg2r/ro7b7/Zg9raLvzpD8P40EfWA9Cn7xY+eMB6nvhTw7/yVolmuKS+wJHATICI2BoRbwKTgVkp2yxgSlqfDFwTmUeBfmle8Sa15V3T04HBwEGp5rgK6FmaISLmkX3h5cDVks4kC7L3lgTeAyLinDYsd7vy6D19mHTKOgAmnbKOR+7uU3CJrN4bq3qx34fX06NHDRAcOO4Nli7J7hiNn7CCx/80lG1bq2M4srZS3xtegZrlKOAN4L8kPS3pqjQ17tCS+cBXsr2CNhxYWnL8spTWpLYMln2B1RGxTdIEGqkdStobWBURvwSuAsYCjwLjJe2b8uwh6YNtWO7CXPSLJUy/42VGfGAzv5m/kGM/vZYbfz6EsUds4FcPvcDYIzZw08+HlD+RtYmXFvbn4QeG8bP/msd//PpBugh+Pyf7a37kxOXMu3dEwSVsn1rQGz6o/lZbWqaVnKYbWby4IiI+CrzL9iY38Lfpb2Nny9mWbbhrgTskPUt23/HFRvIcBXxd0jZgA3BmRLwh6XPA9ZLq29eXAH9p/SIX69Ivvuf/JwBcdOoH2rgklte1M/fn2pn7vyf94gvGF1Ca9i9C1OR/LGhNRIxrYt8yYFlEPJa2byYLlqskDYuIFamZXf+s3XJgZMnxI1Jak1otWEZE7wbba4DDmssbEbPYfn+hdP/9wMdaoZhmVrBKPJQeESslLZW0X0S8BEwEFqZlKnBp+pyTDrkd+JKkG4BDgLdKmuuNcu+AmRWmwm/wXABcK6k78CpwFtmtxpsknQMsAU5Jee8ETgAWARtT3mY5WJpZoSoVLCNiAdBYM31iI3kDOL8l53ewNLPCePBfM7Oc2sOrjHk4WJpZYSKgxoP/mpmV52a4mVkZvmdpZpZTtQwG42BpZoVyB4+ZWRkRvmdpZpaDqHVvuJlZeb5naWZWRjXN7uhgaWbFiey+ZTVwsDSzQrk33MysjHAHj5lZPm6Gm5nl4N5wM7MyIhwszcxy8aNDZmY5VMs9y+rohjKzDikQdXVdci3lSFos6VlJCyTNT2kDJN0r6eX02T+lS9LlkhZJekbS2HLnd7A0s0JFziWnCRExpmR+8YuAuRExGpibtgGOB0anZRpwRbkTO1iaWXFSB0+eZSdNBmal9VnAlJL0ayLzKNBP0rDmTuRgaWbFyl+1HCRpfskyrZEz3SPpyZJ9QyNiRVpfCQxN68OBpSXHLktpTXIHj5kVqgW1xjUlzevG/H1ELJc0BLhX0os7XidC0k53JzUZLCX9P5q5VRARX97Zi5qZQRp1qK4yjw5FxPL0uVrSbcDBwCpJwyJiRWpmr07ZlwMjSw4fkdKa1FzNcv7OF9vMLIcAKvCcpaQ9gC4R8U5aPwb4LnA7MBW4NH3OSYfcDnxJ0g3AIcBbJc31RjUZLCNiVum2pN0jYuPOfhkzs8ZU6DnLocBtkiCLa9dFxF2SngBuknQOsAQ4JeW/EzgBWARsBM4qd4Gy9ywlHQbMBHoDe0k6EDg3Ir7Y8u9jZtZABYJlRLwKHNhI+lpgYiPpAZzfkmvk6Q3/KXAssDZd5M/AkS25iJlZ4/I9NtQe3h/P1RseEUtT9bZebesUx8w6nSp53TFPsFwq6XAgJO0GfAV4oXWLZWadQkBUqDe8teVphn+BrG0/HPgrMIYWtvXNzJqmnEuxytYsI2INcHoblMXMOqMqaYaXrVlKer+kOyS9IWm1pDmS3t8WhTOzTqDCI2m0ljzN8OuAm4BhwP8AZgPXt2ahzKyTqH8oPc9SsDzBcveI+HVE1KTlN0DP1i6YmXUOEfmWojX3bviAtPp7SRcBN5D9f+BUsqffzcx2XZX0hjfXwfMkWXCs/ybnluwL4OLWKpSZdR47Pw5Q22ru3fBRbVkQM+uE2knnTR653uCR9GHgAEruVUbENa1VKDPrLNpH500eeQbS+BZwFFmwvJNs7oqHAAdLM9t1VVKzzNMbfhLZqB0rI+IsspE9+rZqqcys86jLuRQsTzN8U0TUSaqR1IdspOGR5Q4yMyurQoP/toU8wXK+pH7AL8l6yDcAj7Rqqcys06j63vB6JYP8XinpLqBPRDzTusUys06j2oOlpLHN7YuIp1qnSGZm7U9zNcvLmtkXwNEVLkvFqEd3uu7lx0Srye/m3VZ0EayFug6rzHkq2QyX1JVsssXlEXGipFFkbx8OJLuNeEZEbJXUg+yJnoPIZoE4NSIWN3fu5h5Kn1Ch8puZNS6o9OuO9YOT90nbPwKmR8QNkq4EzgGuSJ/rI2JfSaelfKc2d+I8jw6ZmbWeCg3RJmkE8EngqrQtshbwzSnLLGBKWp+ctkn7J6rB3DkNOViaWaEU+RZgkKT5Jcu0Bqf6KfANtj+VORB4MyJq0vYyshkfSJ9LAdL+t1L+JuV63dHMrNXkv2e5JiLGNbZD0onA6oh4UtJRFSrZDvK87iiyaSXeHxHflbQX8L6IeLw1CmRmnUxlOnjGA/8o6QSyMSz6AD8D+knqlmqPI4DlKf9yspdrlknqRvZW4trmLpCnGf4L4DDg02n7HeA/WvhFzMzeI28TvFyPeURcHBEjImIf4DTg/og4HXiA7JVtgKnAnLR+e9om7b8/ovkhhvMEy0Mi4nxgcyrUeqB7juPMzMqrU75l53wTuFDSIrJ7kjNT+kxgYEq/ELio3Iny3LPclp5dCgBJg2kXr7WbWUdQ6dcdI+JB4MG0/ipwcCN5NgMnt+S8eWqWlwO3AUMk/YBseLYftuQiZmZNqpLZHfO8G36tpCfJhmkTMCUiXmj1kplZx5fjfmR7kac3fC9gI3BHaVpEvN6aBTOzTqKjBEvgd2yfuKwnMAp4Cfi7ViyXmXUSqpIekDzN8I+UbqfRiL7YRHYzsw6pxW/wRMRTkg5pjcKYWSfUUZrhki4s2ewCjAX+2molMrPOoyN18AB7lqzXkN3DvKV1imNmnU5HCJbpYfQ9I+Jf2qg8ZtbZVHuwrH/5XNL4tiyQmXUeomP0hj9Odn9ygaTbgdnAu/U7I+LWVi6bmXV0HeyeZU+yoYuOZvvzlgE4WJrZrusAwXJI6gl/ju1Bsl6VfD0za/eqJJo0Fyy7Ar3ZMUjWq5KvZ2btXUdohq+IiO+2WUnMrHPqAMGyovNTmpm9R3SM3vCJbVYKM+u8qr1mGRHr2rIgZtY5Vcs9S88bbmbFqsBI6ZJ6Snpc0p8lPS/pOyl9lKTHJC2SdKOk7im9R9pelPbvU66YDpZmVpy8gbJ87XMLcHREHAiMAY6TdCjwI2B6ROwLrAfOSfnPAdan9OkpX7McLM2sMKJiU+FGRGxIm7ulJcheprk5pc8CpqT1yWmbtH+ipGY7tR0szaxQLQiWgyTNL1mm7XAeqaukBcBq4F7gFeDNiKhJWZYBw9P6cGApQNr/FtlUuU1q8eC/ZmYVlb+DZ01EjGvyNBG1wBhJ/chmpN1/1wu3nWuWZlasCk+FGxFvAg8AhwH9JNVXCkcAy9P6cmAkZCOsAX3JxsBokoOlmRUnZxO83D1LSYNTjRJJvYBPAC+QBc2TUrapwJy0fnvaJu2/PyKavYqb4WZWrMo8ZzkMmJUGLO8C3BQR/y1pIXCDpO8DTwMzU/6ZwK8lLQLWAaeVu4CDpZkVqhKvO0bEM8BHG0l/FTi4kfTNwMktuYaDpZkVqlre4HGwNLPitLDzpkgOlmZWLAdLM7Pm1b/BUw0cLM2sUKqrjmjpYGlmxfE9SzOzfNwMNzPLw8HSzKw81yzNzPJwsDQzK6ODzO5oZtaq/JylmVlezY+M1m44WJpZoVyztF02+aRXOPbExUhw13/vzZzZ+3L2ec9xyOErqanpworlezD90o/y7obuRRe1U7t1xmB+f90AJBi1/2b+efrr/P66gdx21WBWLO7BTc8+S9+BtQC8/nIPfnLhXix6thdTv7mCk897o+DSF6yKHkpvk5HSJQ2UtCAtKyUtL9n2v/RG7D3qbY49cTFfO/fjnH/2BA4+bBXDhm/g6flDOO9zR3P+WUezfFlvTvnsy0UXtVNbs2I3fjtzED///V+Y8cBL1NbBg3P683cfe5dLb3yFoSO27pC/T/9azvveMv73F1YXVOL2R3X5lqK1SbCMiLURMSYixgBXks3jOyYtW0vmyLBk5N7v8NIL/dmypRt1tV14bsFAxh+5gqefGEJdbfazvfh8fwYN3lRwSa22RmzZ3IXaGtiyqQsDh25j349s4n0jt74nb79BNew3ZhPd/Df+b6olWBb2k0m6GthMNrrxw5LeBjZExI/T/ueAEyNisaTPAl8GugOPAV9MM7l1WEte68PUf1rInn22snVLF8YduoqXX+q3Q55jTljCvPtHFFRCAxg0bBsnnbeaMz52AD16BmM//jYHHfVO0cWqHkHVdPAUPWHZCODwiLiwqQySPgScCoxPNdNa4PRG8k2rn094a23117aWLtmT2deN5vuXPcz3fvwIry7qS13d9jngTz3jJWpru/DAvQ6WRXrnza48cndfZj22kOuefo7NG7sy95b+RRerqlRowrKRkh6QtFDS85K+ktIHSLpX0svps39Kl6TLJS2S9IykseXKWXSwnJ2jhjgROAh4Ik2gPhF4f8NMETEjIsZFxLjuXXu1QlHb3j2/24ev/NMEvnHBEWx4pzvLl/YGYNJxSzj4sJX8+/cOIntSzYry9B97876RW+k3sJZuu8H4E95k4fw9ii5WdanMVLg1wD9HxAHAocD5kg4ALgLmRsRoYG7aBjgeGJ2WacAV5S5QdLB8t2S9hh3L0zN9CphVco9zv4j4dlsVsEh9+20BYPCQjRx+5F958L4RHHTwKk76zCK+c/GhbNniG19FGzJ8Gy88tTubN4oIWPDQnuy17+aii1U16h9K39WaZUSsiIin0vo7ZNPgDgcmA7NStlnAlLQ+GbgmMo+SzS8+rLlrtKd/bYuBEwFSlXhUSp8LzJE0PSJWSxoA7BkRS4opZtv5t+89Tp++W6mpEb+YfiDvbujOeV99ht261/GDnzwMwEsLB/Dzy8YUXNLOa/+xGznik29x/rH70bVbsO+HN3H8Z9fy26sGMfuKIaxbvRtfmLQ/Bx/9Nl+7bCnrVnfjguM/yMZ3uqIu8NurBjPjwRfZY8920INRhIiWDP47SNL8ku0ZETGjYSZJ+5D1hTwGDI2IFWnXSmBoWh8OLC05bFlKW0ET2lOwvAU4U9LzZF/yLwARsVDSJcA9kroA24DzgQ4fLL9xwRHvSfv8Zz5RQEmsOWd+fSVnfn3lDmlTPr+GKZ9f8568A4bUcO2TC9uqaNUhf//OmogY11wGSb3JYslXI+JtafttqogIaecfgW/zYNlUEzoiNgHHNLHvRuDGViyWmRWkUm/wSNqNLFBeGxG3puRVkoZFxIrUzK5/wHU5MLLk8BEprUlF37M0s84sgLrItzRDWRVyJvBCRPykZNftwNS0PhWYU5J+ZuoVPxR4q6S53qj21Aw3s86oMjXL8cAZwLPpqRmAfwUuBW6SdA7ZrbtT0r47gROARcBG4KxyF3CwNLNCVaIZHhEP0fRzdBMbyR9kfR+5OViaWaE8Fa6ZWTlVNOqQg6WZFSZ7KL06oqWDpZkVq0qex3ewNLNCuWZpZlaO71mameXRonfDC+VgaWbFcjPczKyMaB9TRuThYGlmxXLN0swsh+qIlQ6WZlYs1VVHO9zB0syKE/ihdDOzckT4oXQzs1wcLM3McnCwNDMrw/cszczyqZbecE9YZmYFiqwZnmcpQ9KvJK2W9FxJ2gBJ90p6OX32T+mSdLmkRZKekTS23PkdLM2sOEHFgiVwNXBcg7SLgLkRMRqYm7YBjgdGp2UacEW5kztYmlmx6nIuZUTEPGBdg+TJwKy0PguYUpJ+TWQeBfqlecWb5HuWZlaoFjxnOUjS/JLtGRExo8wxQ0vmA18JDE3rw4GlJfmWpbQm5w53sDSzYuUPlmsiYtzOXyZC2vmJdx0szaw4EVDbqr3hqyQNi4gVqZm9OqUvB0aW5BuR0prke5ZmVqzKdfA05nZgalqfCswpST8z9YofCrxV0lxvlGuWZlasCr3BI+l64Ciye5vLgG8BlwI3SToHWAKckrLfCZwALAI2AmeVO7+DpZkVJ4AKzcETEZ9uYtfERvIGcH5Lzu9gaWYFCojqeIPHwdLMihO0dgdPxThYmlmxPOqQmVkODpZmZuXs0mNBbcrB0syKE0CVDNHmYGlmxXLN0sysnFZ/3bFiHCzNrDgB4ecszcxyqNAbPK3NwdLMiuV7lmZmZUS4N9zMLBfXLM3MygmitrboQuTiYGlmxangEG2tzcHSzIrlR4fMzJoXQLhmaWZWRnjwXzOzXKqlg0dRJd32LSHpDbLJiTqiQcCaogthLdJRf7O9I2LwrpxA0l1kfz55rImI43bleruiQwbLjkzS/F2ZaN7ann+zjsHzhpuZ5eBgaWaWg4Nl9ZlRdAGsxfybdQC+Z2lmloNrlmZmOThYmpnl4IfSCyapFni2JGlKRCxuIu+GiOjdJgWzZkkaCMxNm+8DaoE30vbBEbG1kIJZq/E9y4K1JAA6WLZPkr4NbIiIH5ekdYuImuJKZZXmZng7I6m3pLmSnpL0rKTJjeQZJmmepAWSnpN0REo/RtIj6djZkhxY25CkqyVdKekx4P9K+rakfynZ/5ykfdL6ZyU9nn7D/5TUtaBiW04OlsXrlf7BLJB0G7AZ+FREjAUmAJdJUoNjPgPcHRFjgAOBBZIGAZcAk9Kx84EL2+5rWDICODwimvyzl/Qh4FRgfPoNa4HT26h8tpN8z7J4m9I/GAAk7Qb8UNKRQB0wHBgKrCw55gngVynvbyNigaSPAwcAD6fY2h14pI2+g203OyLKjQwxETgIeCL9Vr2A1a1dMNs1Dpbtz+nAYOCgiNgmaTHQszRDRMxLwfSTwNWSfgKsB+6NiE+3dYFtB++WrNewY+ut/ncUMCsiLm6zUtkuczO8/ekLrE6BcgKwd8MMkvYGVkXEL4GrgLHAo8B4SfumPHtI+mAbltveazHZb4OkscColD4XOEnSkLRvQPpNrR1zzbL9uRa4Q9KzZPcdX2wkz1HA1yVtAzYAZ0bEG5I+B1wvqUfKdwnwl9YvsjXhFuBMSc8Dj5F+i4hYKOkS4B5JXYBtwPl03GEFOwQ/OmRmloOb4WZmOThYmpnl4GBpZpaDg6WZWQ4OlmZmOThYdlKSakveLZ8tafddONfVkk5K61dJOqCZvEdJOnwnrrE4vdKZK71Bng0tvNYO73SbgYNlZ7YpIsZExIeBrcAXSndK2qlncCPi8xGxsJksRwEtDpZmRXOwNIA/AvumWt8fJd0OLJTUVdK/S3pC0jOSzgVQ5ueSXpJ0HzCk/kSSHpQ0Lq0fl0ZA+nMaSWkfsqD8tVSrPULSYEm3pGs8IWl8OnagpHskPS/pKrJXBJsl6beSnkzHTGuwb3pKnytpcEr7gKS70jF/lLR/Jf4wrWPyGzydXKpBHg/clZLGAh+OiNdSwHkrIj6W3gp6WNI9wEeB/cgG7hgKLAR+1eC8g4FfAkemcw2IiHWSrqRk7EdJ1wHTI+IhSXsBdwMfAr4FPBQR35X0SeCcHF/n7HSNXmSDVNwSEWuBPYD5EfE1Sf8nnftLZBOJfSEiXpZ0CPAL4Oid+GO0TsDBsvPqJWlBWv8jMJOsefx4RLyW0o8B/mf9/Uiy99ZHA0cC16fRdf4q6f5Gzn8oMK/+XBGxrolyTAIOKBmFrk8ah/NI4H+lY38naX2O7/RlSZ9K6yNTWdeSjd50Y0r/DXBrusbhwOySa/fArAkOlp3XDkPDAaSgUTpqjoALIuLuBvlOqGA5ugCHRsTmRsqSm6SjyALvYRGxUdKDNBitqUSk677Z8M/ArCm+Z2nNuRs4L42biaQPStoDmAecmu5pDiMbpLihR4EjJY1Kxw5I6e8Ae5bkuwe4oH5DUn3wmkc2yDGSjgf6lylrX2B9CpT7k9Vs63UB6mvHnyFr3r8NvCbp5HQNSTqwzDWsE3OwtOZcRXY/8ilJzwH/SdYauQ14Oe27hkYGGY6IN4BpZE3eP7O9GXwH8Kn6Dh7gy8C41IG0kO298t8hC7bPkzXHXy9T1ruAbpJeAC4lC9b13gUOTt/haOC7Kf104JxUvueB90zhYVbPow6ZmeXgmqWZWQ4OlmZmOThYmpnl4GBpZpaDg6WZWQ4OlmZmOThYmpnl8P8BikuHthnoJwcAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "inceptionv3MAINPrePro500.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}